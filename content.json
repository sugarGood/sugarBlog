{"meta":{"title":"SugarGood","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2023-06-09T06:00:28.547Z","updated":"2023-06-09T05:04:07.772Z","comments":false,"path":"/404.html","permalink":"http://example.com/404.html","excerpt":"","text":""},{"title":"关于","date":"2023-06-09T06:00:28.555Z","updated":"2023-06-09T05:04:07.773Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"友情链接","date":"2023-06-09T06:31:18.184Z","updated":"2023-06-09T06:31:18.184Z","comments":false,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""},{"title":"书单","date":"2023-06-09T06:00:28.562Z","updated":"2023-06-09T05:04:07.773Z","comments":false,"path":"books/index.html","permalink":"http://example.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2023-06-09T06:00:28.569Z","updated":"2023-06-09T05:04:07.773Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-06-09T06:00:28.600Z","updated":"2023-06-09T05:04:07.775Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-06-09T06:00:28.588Z","updated":"2023-06-09T05:04:07.775Z","comments":false,"path":"repository/index.html","permalink":"http://example.com/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"操作系统","slug":"操作系统","date":"2023-07-07T13:29:41.317Z","updated":"2023-07-07T13:33:46.315Z","comments":true,"path":"2023/07/07/操作系统/","link":"","permalink":"http://example.com/2023/07/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"硬件结构 CPU程序执行流程CPU包括三个部分，运算单元、数据单元、控制单元。运算单元负责计算，数据单元负责暂时存放数据和运算结果，控制单元可以获取指令并执行，这个指令会指导运算单元取出数据单元中的某几个数据，计算出个结果，然后放在数据单元的某个地方。进程都有自己的内存空间，互相隔离，程序会分别加载到进程 A 和进程 B 的内存空间里面，形成各自的代码段，程序运行的过程中要操作的数据和产生的计算结果，都会放在数据段里面。计算流程：CPU中有一个指令指针寄存器，它里面存放的是下一条指令在内存中的地址。控制单元会不停地将代码段的指令拿进来，先放入指令寄存器。指令一般分为两部分，一部分是做什么操作，一部分是操作哪些数据。要执行这条指令，就要把第一部分交给运算单元，第二部分交给数据单元。数据单元根据数据的地址从数据段里读到数据寄存器里。运算单元做完运算，产生的结果会暂存在数据单元的数据寄存器里。最终，会有指令将数据写回内存中的数据段。 那 CPU 执行程序的过程如下： 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。 第二步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行； 第三步，CPU 执行完指令后，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4； 简单总结一下就是，一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的指令周期。 当有多个进程需要执行时，CPU 里有两个寄存器，专门保存当前处理进程的代码段的起始地址，以及数据段的起始地址。进程切换就是通过这个定位到进程上次执行到的位置。 常见的寄存器种类： 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。 指令寄存器，用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。 总线总线是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种： 地址总线，用于指定 CPU 将要操作的内存地址； 数据总线，用于读写内存的数据； 控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线； 当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线： 首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据； 地址总线的位数，决定了能访问的地址范围到底有多广。而数据总线的位数，决定了一次能拿多少个数据进来。 内存容量为4GB，即内存单元的地址宽度为32位。字长为32位即要求数据总线的宽度为32位，因此地址总线和数据总线的宽度都为32。2的32次方等于102410241024*4 &#x3D; 4GB 线路位宽与 CPU 位宽线路位宽数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，高压电压则表示 1。 高低高这样的信号，其实就是 101 二进制数据。如果只有一条线路，就意味着每次只能传递 1 bit 的数据，即 0 或 1，那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。 这样一位一位传输的方式，称为串行，下一个 bit 必须等待上一个 bit 传输完成才能进行传输。当然，想一次多传一些数据，增加线路即可，这时数据就可以并行传输。 为了避免低效率的串行传输的方式，线路的位宽最好一次就能访问到所有的内存地址。 如果地址总线只有 1 条，那每次只能表示 「0 或 1」这两种地址，所以 CPU 能操作的内存地址最大数量为 2（2^1）个（注意，不要理解成同时能操作 2 个内存地址）；如果地址总线有 2 条，那么能表示 00、01、10、11 这四种地址，所以 CPU 能操作的内存地址最大数量为 4（2^2）个。 CPU位宽CPU位宽越大，一次可以计算的bit数就越多。CPU 的位宽最好不要小于线路位宽，32 位 CPU 一次最多只能操作 32 位宽的地址总线和数据总线。 64 位 CPU 性能并不比 32 位 CPU 高很多，很少应用需要算超过 32 位的数字，所以如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来。 a&#x3D;1+2的执行过程程序编译过程中，编译器通过分析代码，发现 1 和 2 是数据，于是程序运行时，内存会有个专门的区域来存放这些数据，这个区域就是「数据段」。如下图，数据 1 和 2 的区域位置：（0X表示这是个16进制数） 数据 1 被存放到 0x100 位置； 数据 2 被存放到 0x104 位置； 注意，数据和指令是分开区域存放的，存放指令区域的地方称为「正文段」。编译器会把 a &#x3D; 1 + 2 翻译成 4 条指令，存放到正文段中，这 4 条指令被存放到了 0x200 ~ 0x20c 的区域中：● 0x200 的内容是 load 指令将 0x100 地址中的数据 1 装入到寄存器 R0；● 0x204 的内容是 load 指令将 0x104 地址中的数据 2 装入到寄存器 R1；● 0x208 的内容是 add 指令将寄存器 R0 和 R1 的数据相加，并把结果存放到寄存器 R2；● 0x20c 的内容是 store 指令将寄存器 R2 中的数据存回数据段中的 0x108 地址中，这个地址也就是变量 a 内存中的地址编译完成后，具体执行程序的时候，程序计数器会被设置为 0x200 地址，然后依次执行这 4 条指令。上面的例子中，由于是在 32 位 CPU 执行的，因此一条指令是占 32 位大小，所以你会发现每条指令间隔 4 个字节（地址每1代表一个字节 、8个bit 、一个bit存放一个二进制数 8bit也就是8位二进制数表示的数的范围为255）。而数据的大小是根据你在程序中指定的变量类型，比如 int 类型的数据则占 4 个字节，char 类型的数据则占 1 个字节。 指令的执行速度CPU 的硬件参数都会有 GHz 这个参数，比如一个 1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期 ,1GHz的时间周期时间为1&#x2F;1G。对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。 而时间周期时间就是CPU主频，如今CPU主频提升已经到了瓶颈，所以可以通过减少** CPU 时钟周期数量**，一样也是能提升程序的性能的。**CPU 时钟周期数量 &#x3D; **指令数 x 每条指令的平均时钟周期数(CPI)CPI：表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少； CPU数据存储器 寄存器最靠近 CPU 的控制单元和逻辑计算单元的存储器，就是寄存器了，它使用的材料速度也是最快的，因此价格也是最贵的，那么数量不能很多。寄存器的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写，CPU 时钟周期跟 CPU 主频息息相关，比如 2 GHz 主频的 CPU，那么它的时钟周期就是 1&#x2F;2G，也就是 0.5ns（纳秒） CPU CacheCPU Cache 用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。 L1 高速缓存L1 高速缓存的访问速度几乎和寄存器一样快，通常只需要 2~4 个时钟周期，而大小在几十 KB 到几百 KB 不等。每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成指令缓存和数据缓存。 L2 高速缓存L2 高速缓存同样每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU 核心 更远，它大小比 L1 高速缓存更大，CPU 型号不同大小也就不同，通常大小在几百 KB 到几 MB 不等，访问速度则更慢，速度在 10~20 个时钟周期。 L3 高速缓存L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，大小也会更大些，通常大小在几 MB 到几十 MB 不等，具体值根据 CPU 型号而定。访问速度相对也比较慢一些，访问速度在 20~60个时钟周期。 内存内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问的速度会更慢，内存速度大概在 200~300 个 时钟周期之间。 SSD&#x2F;HDD 硬盘SSD（Solid-state disk） 就是我们常说的固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。内存的读写速度比 SSD 大概快 10~1000 倍。当然，还有一款传统的硬盘，也就是机械硬盘（Hard Disk Drive, HDD），它是通过物理读写的方式来访问数据的，因此它访问速度是非常慢的，它的速度比内存慢 10W 倍左右。由于 SSD 的价格快接近机械硬盘了，因此机械硬盘已经逐渐被 SSD 替代了。 存储器的层次关系CPU 并不会直接和每一种存储器设备直接打交道，而是每一种存储器设备只和它相邻的存储器设备打交道。比如，CPU Cache 的数据是从内存加载过来的，写回数据的时候也只写回到内存，CPU Cache 不会直接把数据写到硬盘，也不会直接从硬盘加载数据，而是先加载到内存，再从内存加载到 CPU Cache 中。 当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。 程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。它们之间的层级关系，如下图 cpu数据读取CPU Cache 是由很多个 Cache Line 组成的，Cache Line 是 CPU 从内存读取数据的基本单位，而 Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成。 CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，在 CPU Cache 中的，这样一小块一小块的数据，称为** Cache Line**（缓存块）。比如，有一个 int array[100] 的数组，当载入 array[0] 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会**顺序加载**数组元素到 array[15]，意味着 array[0]~array[15] 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。 那 CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢？CPU 访问内存数据时，是一小块一小块数据读取的，具体这一小块数据的大小，取决于 coherency_line_size 的值，一般 64 字节。在内存中，这一块的数据我们称为内存块（Block），读取的时候我们要拿到数据所在内存块的地址。内存块的地址和cpu line(缓存块)的地址有一个映射关系，取模，比如总共Cpu cache中总共由8个cpu line,当需要访问15号内存块的时候通过15%8&#x3D;7得出 需要的数据在可能在7号Cpu line中。 但是取模算法显然是有缺陷的，可能会出现重复，比如7 2 3内存块的映射cpu line都一样。 因此，为了区别不同的内存块，在对应的 CPU Line 中我们还会存储一个组标记（Tag）。这个组标记会记录当前 CPU Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。 除了组标记信息外，CPU Line 还有两个信息： 一个是，从内存加载过来的实际存放数据（Data）。 另一个是，有效位（Valid bit），它是用来标记对应的 CPU Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。 CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个字（Word）。那怎么在对应的 CPU Line 中数据块中找到所需的字呢？答案是，需要一个偏移量（Offset）。 因此，一个内存的访问地址，包括组标记、CPU Cache Line 索引、偏移量这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由索引 + 有效位 + 组标记 + 数据块组成。 读取步骤 根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Cache Line 的地址； 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行； 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行； 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。 由于cpu cache的速度远大于内存，所以我们如果提升cpu cache的命中率，自然也就会加快代码的执行效率。 cpu数据写入数据不光是只有读操作，还有写操作，那么如果数据写入 Cache 之后，内存与 Cache 相对应的数据将会不同，问题来了，那在什么时机才把 Cache 中的数据写回到内存呢？ 写直达:保持内存与 Cache 一致性最简单的方式是，把数据同时写入内存和 Cache 中，这种方法称为写直达,但是这样写操作将会花费大量的时间，无疑性能会受到很大的影响。 写回:在写回机制中，当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提高系统的性能。意思就是一般情况数据只写入cacheBlock，并把数据标记为脏，(表示和内存不一致)，但是当需要写入的数据不在cpu cache里面，就需要定位到需要写入的数据的Cache block(数据块)位置，如果位置上已有其他数据，就需要判断数据是否为脏的，如果为脏的就要先将该数据写回内存，然后在将要新写入的数据写入到cache block，并且标记为脏。 cpu缓存一致性cpu多核的情况， L1 L2 cache是各个核心独有的，那么会带来多核心的缓存一致性（Cache Coherence） 的问题当不同核心操作同一个数据时，如果使用的写回策略，就有可能核心之间数据不一致 举例，两个核心A、B操作内存中数字i&#x3D;0 A核心执行了i++，如果使用了写回策略，此时只有A核心L1&#x2F;L2 cache中的数据为1 并标记为脏。B核心读取的时候 读到的将会是错误的值。 解决方案第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（Write Propagation）；第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串行化（Transaction Serialization）。要实现事务串行化，要做到 2 点： CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心； 要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。 总线嗅探当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache。可以发现，总线嗅探方法很简单， CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这无疑会加重总线的负载。另外，总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串行化。于是，有一个协议基于总线嗅探机制实现了事务串行化，也用状态机机制降低了总线带宽压力，这个协议就是 MESI 协议，这个协议就做到了 CPU 缓存一致性。 MESI协议MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：Modified，已修改Exclusive，独占Shared，共享Invalidated，已失效 我们举个具体的例子来看看这四个状态的转换： 当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的； 然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的； 当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。 如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。 如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。 所以，可以发现当 Cache Line 状态是「已修改」或者「独占」状态时，修改更新其数据不需要发送广播给其他 CPU 核心，这在一定程度上减少了总线带宽压力。 CPU伪共享问题现在假设有一个双核心的 CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 long 的变量 A 和 B，这个两个数据的地址在物理内存上是连续的，如果 Cahce Line 的大小是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这两个数据是位于同一个 Cache Line 中，又因为 CPU Line 是 CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU 核心中各自 Cache 中。假设 1 号核心绑定了线程 A，2 号核心绑定了线程 B，线程 A 只会读写变量 A，线程 B 只会读写变量 B。 1 号核心读取变量 A，由于 CPU 从内存读取数据到 Cache 的单位是 Cache Line，也正好变量 A 和 变量 B 的数据归属于同一个 Cache Line，所以 A 和 B 的数据都会被加载到 Cache，并将此 Cache Line 标记为「独占」状态。 接着，2 号核心开始从内存里读取变量 B，同样的也是读取 Cache Line 大小的数据到 Cache 中，此 Cache Line 中的数据也包含了变量 A 和 变量 B，此时 1 号和 2 号核心的 Cache Line 状态变为「共享」状态。 1 号核心需要修改变量 A，发现此 Cache Line 的状态是「共享」状态，所以先需要通过总线发送消息给 2 号核心，通知 2 号核心把 Cache 中对应的 Cache Line 标记为「已失效」状态，然后 1 号核心对应的 Cache Line 状态变成「已修改」状态，并且修改变量 A。 之后，2 号核心需要修改变量 B，此时 2 号核心的 Cache 中对应的 Cache Line 是已失效状态，另外由于 1 号核心的 Cache 也有此相同的数据，且状态为「已修改」状态，所以要先把 1 号核心的 Cache 对应的 Cache Line 写回到内存，然后 2 号核心再从内存读取 Cache Line 大小的数据到 Cache 中，最后把变量 B 修改到 2 号核心的 Cache 中，并将状态标记为「已修改」状态。 所以，可以发现如果 1 号和 2 号 CPU 核心这样持续交替的分别修改变量 A 和 B，就会重复最后两个步骤，Cache 并没有起到缓存的效果，虽然变量 A 和 B 之间其实并没有任何的关系，但是因为同时归属于一个 Cache Line ，这个 Cache Line 中的任意数据被修改后，都会相互影响，从而出现一直重复最后两个步骤。因此，这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为伪共享（False Sharing）。 CPU如何选择线程CPU密集型和IO密集型为什么有时候线程数超过CPU内核数会更快呢？**CPU密集型 ** CPU密集型会消耗掉大量的CPU资源，例如需要大量的计算，一些复杂运算，逻辑处理之类的。这个时候CPU就卯足了劲在运行，这个时候切换线程，反而浪费了切换的时间，效率不高。 就像你的大脑是CPU，你本来就在一本心思地写作业，多线程这时候就是要你写会作业，然后立刻敲一会代码，然后在P个图，然后在看个视频，然后再切换回作业。emmmm，过程中你还需要切换（收起来作业，拿出电脑，打开VS…）那你的作业怕是要写到挂科。。。这个时候不太适合使用多线程，你就该一门心思地写作业~ IO密集型 涉及到网络、磁盘IO的都是IO密集型，这个时候CPU利用率并不高，这个时候适合使用多线程。 同样以你的大脑为例，IO密集型就是“不烧脑”的工作。例如你需要陪小姐姐或者小哥哥聊天，还需要下载一个VS，还需要看我（黑哥）的博客。这个时候如果使用多线程的话会怎么做？ 咦？小哥哥（小姐姐）给你发消息了，回一下TA，然后呢？TA给你回消息肯定需要时间，这个时候你就可以搜索VS的网站，先下安装包，然后一看，哎呦，TA还没给你回消息，然后看会你黑哥的博客。小哥哥（小姐姐）终于回你了，你回一下TA，接着看我的博客，这就是类似于IO密集型。你可以在不同的“不烧脑”的工作之间切换，来达到更高的效率。而不是小姐姐不回我的信息，我就干等，啥都不干，就等，这个效率可想而知，也许，小姐姐（小哥哥）根本就不会回复你~ 高并发、任务执行时间短的业务，CPU密集型的，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换。 并发不高、任务执行时间长的业务这就需要区分开看了：a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以适当加大线程池中的线程数目，让CPU处理更多的业务b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换（其实从一二可以看出无论并发高不高，对于业务中是否是cou密集还是I&#x2F;O密集的判断都是需要的当前前提是你需要优化性能的前提下） 3：并发高、业务执行时间长，解决这种类型任务的关键不在于线程池而在于整体架构的设计，可以引入三方中间件进行异步操作。 中断中断是什么中断是一种异步的事件处理机制，可以提高系统的并发处理能力。操作系统收到了中断请求，会打断其他进程的运行，所以中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。打游戏点了个外卖，外卖员电话来，对应着中断请求，接电话表示中断响应程序。 而且，中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。(中断过程中，不会响应其他中断请求)如果有两个外卖员，第一个外卖员的电话时间过程，第二个外卖员打过来在通话中，自然无法打通。 软中断Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。第一个配送员长时间跟我通话，则导致第二位配送员无法拨通我的电话，其实当我接到第一位配送员的电话，可以告诉配送员说我现在下楼，剩下的事情，等我们见面再说（上半部），然后就可以挂断电话，到楼下后，在拿外卖，以及跟配送员说其他的事情（下半部） 比如网卡接受网络包，网卡收到网络包后，会通过硬件中断通知内核有新的数据到了，于是内核就会调用对应的中断处理程序来响应该事件，这个事件的处理也是会分成上半部和下半部。上部分要做到快速处理，所以只要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态，比如把状态更新为表示数据已经读到内存中的状态值。接着，内核会触发一个软中断，把一些处理比较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部，其主要是需要从内存中找到网络数据，再按照网络协议栈，对网络数据进行逐层解析和处理，最后把数据送给应用程序。 上半部直接处理硬件请求，也就是硬中断，主要是负责耗时短的工作，特点是快速执行； 下半部是由内核触发，也就说软中断，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行； 磁盘https://blog.csdn.net/u012637358/article/details/87792272 https://blog.csdn.net/Abner_G&#x2F;article&#x2F;details&#x2F;120523234?utm_medium&#x3D;distribute.pc_relevant.none-task-blog-2defaultbaidujs_baidulandingword~default-0-120523234-blog-121526526.pc_relevant_multi_platform_whitelistv3&amp;spm&#x3D;1001.2101.3001.4242.1&amp;utm_relevant_index&#x3D;3 系统结构内核计算机是由各种外部硬件设备组成的，比如内存、cpu、硬盘等，如果每个应用都要和这些硬件设备对接通信协议，那这样太累了，所以这个中间人就由内核来负责，让内核作为应用连接硬件设备的桥梁，应用程序只需关心与内核交互，不用关心硬件的细节。 现代操作系统，内核一般会提供 4 个基本能力： 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。 内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域：内核空间，这个内存空间只有内核程序可以访问；用户空间，这个内存空间专门给应用程序使用；、 用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，我们常说该程序在用户态执行，而当程序使内核空间时，程序则在内核态执行。 应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程： 内存管理虚拟内存如果两个程序都直接使用物理地址，第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。所以需要避免直接使用物理地址，即让操作系统为每个进程分配独立的一套「虚拟地址」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address）实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address） 进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。主要通过内存分段和内存分页两种方式来转换物理地址。 内存分段虚拟地址由两部分组成，段选择因子和段内偏移量。 段号即为段表的索引，通过段号确定段表中对应的的位置。段内偏移量位于0到段界限之间。如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。 分段机制会把程序的虚拟地址分成4个段，每个段都对应了段表中的一个项，从而可以找到物理地址。如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 &#x3D; 7500 缺点第一个就是内存碎片的问题。第二个就是内存交换的效率低的问题。 内存碎片内存碎片主要分为，内部内存碎片和外部内存碎片。内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片（分配的内存没有用完）。 但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。 我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：游戏占用了 512MB 内存浏览器占用了 128MB 内存音乐占用了 256 MB 内存。这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 &#x3D; 256MB。如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。 解决方案：内存交换：可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。 因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。 内存分页虚拟地址（比如 16 位地址 8196&#x3D;0010 000000000100）分为两部分：虚拟页号（Virtual Page Number，简称 VPN，这里是高 4 位部分）和偏移量（Virtual Page Offset，简称 VPO，这里是低 12 位部分），虚拟地址转换成物理地址是通过页表（page table）来实现的。页表由多个页表项（Page Table Entry, 简称 PTE）组成，一般页表项中都会存储物理页框号、修改位、访问位、保护位和 “在&#x2F;不在” 位（有效位）等信息。 分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，这就是页（Page）。在 Linux 下，每一页的大小为 4KB。 页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作转换过程： 第 1 步：处理器生成一个虚拟地址 VA，通过总线发送到 MMU； 第 2 步：MMU 通过虚拟页号得到页表项的地址 PTEA，通过内存总线从 CPU 高速缓存&#x2F;主存读取这个页表项 PTE； 第 3 步：CPU 高速缓存或者主存通过内存总线向 MMU 返回页表项 PTE； 第 4 步：MMU 先把页表项中的物理页框号 PPN 复制到寄存器的高三位中，接着把 12 位的偏移量 VPO 复制到寄存器的末 12 位构成 15 位的物理地址，即可以把该寄存器存储的物理内存地址 PA 发送到内存总线，访问高速缓存&#x2F;主存； 第 5 步：CPU 高速缓存&#x2F;主存返回该物理地址对应的数据给处理器。 在 MMU 进行地址转换时，如果页表项的有效位是 0，则表示该页面并没有映射到真实的物理页框号 PPN，则会引发一个缺页中断。此时进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。 操作系统会通过页面置换算法选择一个页面将其换出 (swap)，以便为即将调入的新页面腾出位置，如果要换出的页面的页表项里的修改位已经被设置过，也就是被更新过，则这是一个脏页 (Dirty Page)，需要写回磁盘更新该页面在磁盘上的副本，如果该页面是”干净”的，也就是没有被修改过，则直接用调入的新页面覆盖掉被换出的旧页面即可。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。 因为采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。 因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。 在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。 总结一下，对于一个内存地址转换，其实就是这样三个步骤： 把虚拟内存地址，切分成页号和偏移量； 根据页号，从页表里面，查询对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。 通常来说，大多数系统都会选择利用物理内存地址去访问高速缓存，因为高速缓存相比于主存要小得多，所以使用物理寻址也不会太复杂；另外也因为高速缓存容量很小，所以系统需要尽量在多个进程之间共享数据块，而使用物理地址能够使得多进程同时在高速缓存中存储数据块以及共享来自相同虚拟内存页的数据块变得更加直观。 缺点因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了 多级页表我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。 一级页号找到一级页表上的页号，对应到二级页表的地址，通过二级页号，找到该二级页表上最终的物理页号，加上偏移量得到最终的物理地址。 似乎页表项并没有减少，而且还多了4kb的一级页表。当然如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。 每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表 了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）&#x3D; 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？ 因为每个虚拟地址都必须在页表中找到对应的页表项才行，不分级的页表是必须一开始就创建好整个页表的，才能全部对应上，而分级页表的一级页表，1024个页表项就覆盖了整个虚拟地址，需要的时候才会创建二级页表。 我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了。 对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是： 全局页目录项 PGD（Page Global Directory）； 上层页目录项 PUD（Page Upper Directory）； 中间页目录项 PMD（Page Middle Directory）； 页表项 PTE（Page Table Entry） TLB多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件。TLB 可以简单地理解成页表的高速缓存。 所以就出现了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB,通常称为页表缓存、快表。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。 段页式内存管理内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。 段页式内存管理实现的方式： 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页； 这样，地址结构就由段号、段内页号和页内位移三部分组成。 段页式地址变换中要得到物理地址须经过三次内存访问： 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。 CPU数据读取流程总结 CPU要根据用户进程提供的虚拟地址来获取真实数据，但是它并不自己做而是交给了MMU。 MMU也是个聪明的家伙，集成了TLB来存储CPU最近常用的页表项来加速寻址，TLB找不到再去全量页表寻址，可以认为TLB是MMU的缓存。 TLB的容量毕竟有限，为此必须依靠Page Table一起完成TLB Miss情况的查询，并且更新到TLB建立新映射关系 惰性分配程序的局部性原理程序的局部性原理是指程序在执行时呈现出局部性规律，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。局部性原理又表现为：时间局部性和空间局部性。时间局部性是指如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某数据被访问，则不久之后该数据可能再次被访问。空间局部性是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问。 以32位的Linux系统为例，每个进程独立拥有4GB的虚拟地址空间，根据局部性原理没有必要也不可能为每个进程分配4GB的物理地址空间。 所以实际上操作系统分配虚拟内存时，虚拟内存如果没有被访问的话，虚拟内存是不会映射到物理内存的，只有程序运行时用到了才去内存中寻找虚拟地址对应的页帧，找不到才可能进行分配，这就是内存的惰性(延时)分配机制(会触发缺页异常）。 对于一个运行中的进程来说，不是所有的虚拟地址在物理内存中都有对应的页。 缺页中断 PageFault假如目标内存页在物理内存中没有对应的页帧或者存在但无对应权限，CPU 就无法获取数据，这种情况下CPU就会报告一个缺页错误。由于CPU没有数据就无法进行计算，CPU罢工了用户进程也就出现了缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler 处理。 缺页中断会交给PageFaultHandler处理，其根据缺页中断的不同类型会进行不同的处理： Hard Page Fault 也被称为Major Page Fault，翻译为硬缺页错误&#x2F;主要缺页错误，这时物理内存中没有对应的页帧，**需要CPU打开磁盘设备读取到物理内存中，再让MMU建立VA和PA的映射(Swap)**。 Soft Page Fault 也被称为Minor Page Fault，翻译为软缺页错误&#x2F;次要缺页错误，这时物理内存中是存在对应页帧的，只不过可能是其他进程调入的，发出缺页异常的进程不知道而已，此时MMU只需要建立映射即可，无需从磁盘读取写入内存，一般出现在多进程共享内存区域。 Invalid Page Fault 翻译为无效缺页错误，比如进程访问的内存地址越界访问，又比如对空指针解引用内核就会报segment fault错误中断进程直接挂掉。 触发Page Fault的原因可能有很多，归根到底也只有几种大类： 如使用共享内存区域，没有存储VA-&gt;PA的映射但是存在物理页帧的软缺页错误，在Page Table&#x2F;TLB中建立映射关系即可。 访问的地址在物理内存中确实不存在，需要从磁盘&#x2F;swap分区读入才能使用，这种性能影响会比较大，因为磁盘太慢了，尽量使用高性能的SSD来降低延时。 访问的地址内存非法，缺页错误会升级触发SIGSEGV信号结束进程，这种属于可以导致进程挂掉的一种缺页错误。 swap分区当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。这样，系统总是在物理内存不够时，才进行Swap交换。实际上，并不是等所有的物理内存都消耗完毕之后，才去使用swap的空间，什么时候使用是由swappiness 参数值控制。 Swap 其实就是把一块磁盘空间当成内存来用。它可以把进程暂时不用的数据存储到磁盘中（这个过程称为换出，swapout），当进程访问这些内存时，再从磁盘读取这些数据到内存中（这个过程称为换入，swapin），那怎么判定内存的哪些数据是不常用数据需要换出呢，LRU,LFU等都是常用的算法。当物理内存紧张的情况下，当进程访自己已申请的内存地址时，操作系统发现这段内存地址并不在物理内存里，此时就会发生缺页中断，根据内存置换算法选出指定页swapout到磁盘，再将马上要使用到的页swapin到内存，完成了页面的swapin和swapout。 swap分区的大小该怎么设计呢？内存和swap分区的大小1：1是个不会太错的选择，比如4G的物理内存可以考虑配备4G的swap分区。 如果物理内存远小于swap分区大小会有什么后果？这样的配备首先说明物理内存已经远不能处理进程的数据了，需要通过大量借助磁盘来扩展内存才能满足进程需求。这本来就是一个不合理的配比，这会导致内存数据块频繁地被置换到磁盘，产生大量的磁盘IO，导致系统很卡（系统性能都全消耗在缺页中断产生的磁盘IO），上面跑的进程很难得到有效调度。 但反过来，物理内存远大于swap分区并无副作用，比如我们线上 的服务器，物理内存256G，平时活动高峰期内存也完全足够，但为了稳妥起见，我们也还是配了16G的swap分区，作为系统内存异常时的一个最后保障。一些线上服务为了保持高性能一般都会把swap关掉，比如redis。 swappiness的值的大小对如何使用swap分区是有着很大的联系的。swappiness&#x3D;0的时候表示最大限度使用物理内存，然后才是swap空间，swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。linux的基本默认设置为60。当swappines设置得比较大时，你会发现即使系统物理内存还剩余很多，但系统还是倾向于大量使用很慢的swap分区，这就导致系统很卡。但值得注意的是swappiness&#x3D;0并不表示禁用交换分区，而是指尽可能不使用交换分区，但当内存已经耗尽时也会选择使用交换分区，如果不想使用交换分区，那就不要启用swap。 所以一个重要的性能优化经验就是：最好禁用swap。swap应该是针对以前内存小的一种优化,如果是高性能服务，最好禁止 Swap，比如redis，mysql等服务，都是推荐禁用swap的。如果必须开启 Swap，那需要降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。 overcommit惰性分配会引入一个新问题：开空头支票带来的副作用，当进程真正要使用早期申请的这块内存时，系统发现系统的总的可利用的内存（物理内存+swap）已经用完了，没法兑现早期的承诺了，这就是操作系统的overcommit; overcommit是有参数可以调整的，overcommit对应的参数是overcommit_memory。overcommit_memory是一个内核对内存分配的一种策略,它有三个可选值:0、1、2 0- Heuristic overcommit handling： 这是缺省值，它允许overcommit，但过于明目张胆的overcommit会被拒绝，比如malloc一次性申请的内存大小就超过了系统总内存。Heuristic的意思是“试探式的”，内核利用某种算法猜测你的内存申请是否合理，它认为不合理就会拒绝overcommit，并把错误返回给应用进程。而在Redis中这个错误就会表现为“Cannot allocate memory”，然后触发OOM 1 – Always overcommit：表示内核允许超量使用内存直到用完为止，当实在是无法处理时就使用OOM killer杀进程释放内存。 2：在早期分配内存时,内核检查,坚决不超量使用内存，即系统整个内存空间不能超过swap+50%的RAM值(CommitLimit值)，50%是overcommit_ratio默认值，此参数支持修改。1sysctl overcommit_ratio=60 OOM killer:overcommit_memory设置为0&#x2F;1都会存在超配情况，当系统中可利用的内存资源已经耗尽时，有两种选择，一种是直接panic系统，然后几秒钟后LINUX自动重启,这个行为可以通过kernel.panic_on_oom参数设置另外一种选择就是杀死部分进程，从而释放足够的内存来让内存问题得到解决,这就是OOM killer,该机制会杀死分数最高的进程，以求释放内存资源保证系统可以稳定运行。 oom killer通过oom_badness函数来找到可以杀掉的候选进程，然后直接干掉这个进程，尽快解决内存不足的问题，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。 而这个查找过程中，其主要依据是每个进程的oom_score，其选择的算法比较简单，总是选择oom_score比较高，同时优先级比较低的进程去杀。而oom_score在新版本的Linux内核中计算起来十分简单，就是这个进程占用的（物理内存+SWAP）的总和乘以10 在这个函数中，不会返回oom_score为0的进程，因此如果我们把某个进程的oom_score_adj设置为-1000（早期版本的linux oom_score的计算方法不同，因此调整adj的方法略有不同）,那么这个进程的oom_score就会永远为0，也就是说这个进程永远不会被oom killer杀死。这也是我们保护某个进程，不让oom killer杀掉的主要方法。 内存回收oom killer是最后的手段，在oom killer之前还有两种回收的方式，直接内存回收和后台内存回收。 后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒** kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行**。 直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。 如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。 哪些内容可以被回收呢？文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。 文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。 LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中： active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页； inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页； 越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。 通过调整参数swappiness，可以控制文件页和匿名页的回收倾向，swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。 malloc 动态内存分配虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。 进程在用户态时，只能访问用户空间内存；有进入内核态后，才可以访问内核空间的内存；虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。 用户空间的分布情况: 程序文件段，包括二进制可执行代码； 已初始化数据段，包括静态常量； 未初始化数据段，包括未初始化的静态变量； 堆段，包括动态分配的内存，从低地址开始向上增长； 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 ）； 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小。 实际上，malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。 malloc分配的是虚拟内存 malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。 方式一：通过 brk() 系统调用从堆分配内存 方式二：通过 mmap() 系统调用在文件映射区域分配内存； 方式一实现的方式很简单，就是通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间。如下图： 方式二通过 mmap() 系统调用中「私有匿名映射」的方式，在文件映射区分配一块内存，也就是从文件映射区“偷”了一块内存。如下图： malloc() 源码里默认定义了一个阈值： 如果用户分配的内存小于 128 KB，则通过 brk() 申请内存； 如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存； malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放； LRU算法内存的大小是有限的的，不可能无限的缓存数据，对于一些不经常使用的数据会在某些时机淘汰掉。linux中通常使用LRU算法实现。传统的 LRU 算法的实现思路是这样的： 当访问的页在内存里，就直接把该页对应的 LRU 链表节点移动到链表的头部。 当访问的页不在内存里，除了要把该页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的页。 这样还可以保证内存不会满，并且保证常用数据在内存中。 预读失效和缓存污染什么是预读？应用程序读取一个3kb大小的数据，磁盘的读写单位为一页4kb,此时就会读取一整页的数据，但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到),于是就会将附近3页的数据都加载进内存。这样如果后面需要读取这3页的数据时，就不用从磁盘读取了，减少了磁盘io的次数，提高了io吞吐量。其实mysql innodb存储引擎 buffer pool 也有类似的机制。 如果这些被提前加载进来的页，并没有被访问，相当于这个预读工作是白做了，这个就是预读失效。 如何避免预读失效？思路：让预读页和真正被访问的页分开，并且预读页保存时间尽可能短。 linux的解决方案:Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）；预读页就只需要加入到 inactive list 区域的头部，当页被真正访问的时候，才将页插入 active list 的头部。如果预读的页一直没有被访问，就会从 inactive list 移除，这样就不会影响 active list 中的热点数据。 mysql的解决方案：MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域，young 区域 和 old 区域。young 区域与 old 区域在 LRU 链表中的占比关系并不是一比一的关系，而是是** 7 比 3 （**默认比例）的关系。划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。 缓存污染当我们批量读取数据时，这样预读时也会读取大量的数据，此时大量的数据都会被加入到活跃的LRU链表中，这样之前缓存的热点数据会全部被淘汰，如果这些大量的数据后续又没有被访问，那么这个活跃的LRU链表就是被缓存污染了。等热点数据访问时，就会产生大量的磁盘io 这时性能就会急剧下降了。 如何解决缓存污染思路:提高加入活跃LRU链表的门槛，这样数据就不会轻易进入LRU链表，也就保证了活跃LRU链表里的热点数据不会被轻易替换。 Linux设置在内存页被访问第二次时，才会将页从 inactive list 升级到 active list 里。MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断： 如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域； 如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域； 此时我们读取批量数据，如果这些数据只被访问一次，那么就会进入到活跃的LRU链表中(young区域)，也就不会淘汰热点数据了。当然在非活跃链表(old区域)中的数据会很快被淘汰。 进程管理进程运行中的程序就是进程。 进程状态 运行状态（Running）：该时刻进程占用 CPU； 就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行； 创建状态（new）：进程正在被创建时的状态； 结束状态（Exit）：进程正在从系统中消失时的状态； 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 进程控制块(PCB)PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。PCB具体包含的信息: 进程描述信息： 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务； 进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级； 资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。 CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。 相同状态的进程会以链表的形式组织在一起，比如就绪队列、阻塞队列。 进程的操作创建进程操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。过程: 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等； 为该进程分配运行时所必需的资源，比如内存资源； 将 PCB 插入到就绪队列，等待被调度运行； 终止进程进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。 阻塞进程当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。 唤醒进程进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。 进程的上下文切换任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。寄存器中存储了运行任务所必须依赖的环境，这些环境就叫做 CPU 上下文。寄存器上下文：处理器中各个寄存器的内容被称为寄存器上下文（或硬件上下文）。 任务主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。 进程上下文是保存在PCB中的，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行 进程上下文分为用户级上下文和系统级上下文: 用户级上下文：由用户的程序块、数据块、运行时的堆和用户栈（统称为用户堆栈）等组成的用户空间信息被称为用户级上下文。 系统级上下文：由进程标识信息、进程现场信息、进程控制信息（包含进程表、页表、打开文件表等）和系统内核栈等组成的内核空间信息被称为系统级上下文。 上下文切换: 将当前处理器的寄存器上下文保存到当前进程的系统级上下文的现场信息中；(保存了切换时进程的状态) 将新进程系统级上下文中的现场信息作为新的寄存器上下文恢复到处理器的各个寄存器中； 将控制转移到新进程执行。 PC(程序计数器)是寄存器上下文中比较重要的信息之一，当前进程被打断的断点处的PC作为寄存器上下文的一部分被保存在进程现场信息中。当前进程执行到哪个位置的信息是在pc中，然后上下文切换时保存到进程现场信息。这样，下次改进程再被调度到处理器上执行时，就可以从其现场信息中获得断点处的PC，从而能从断点处开始执行。 线程线程是进程当中的一条执行流程。 同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。 线程和进程比较 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销； 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了； 线程上下文切换 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据； 线程的实现主要有三种线程的实现方式： 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理； 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程； 轻量级进程（LightWeight Process）：在内核中来支持用户线程 调度操作系统选择下一个要运行的进程(线程)，称为调度。 调度原则原则一(CPU利用率)：如果运行的程序，发生了 I&#x2F;O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I&#x2F;O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。 原则二(系统吞吐量)：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。 原则三(周转时间)：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。 原则四(等待时间)：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。 原则五(响应时间)：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。 调度算法根据如何处理时钟中断 ，可以把调度算法分为两类：● 非抢占式调度算法 挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。● 抢占式调度算法 挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。 先来先服务（First Come First Serve, FCFS)每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。 最短作业优先（Shortest Job First, SJF）优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。显然对长作业不利，很容易造成一种极端现象。 比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。 高响应比优先 （Highest Response Ratio Next, HRRN）主要是权衡了短作业和长作业。每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行 高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的。 时间片轮转（Round Robin, RR）每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换； 时间片的长度是一个很关键的点：如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；如果设得太长又可能引起对短作业进程的响应时间变长。一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值 最高优先级（Highest Priority First，HPF）它希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行。进程的优先级可以分为，静态优先级和动态优先级： 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 但是依然有缺点，可能会导致低优先级的进程永远不会运行。 多级反馈队列（Multilevel Feedback Queue）这个算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列； 流程: 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 进程间通信每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。 网络系统DMA技术没有DMA技术前,整个I&#x2F;O过程都需要CPU参与，期间CPU干不了其他的事情，如果通过硬盘传输大量数据，CPU肯定忙不过来，于是发明了DMA技术 **直接内存访问（_Direct Memory Access_）** 技术。在进行 I&#x2F;O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。 具体过程： 用户进程调用 read 方法，向操作系统发出 I&#x2F;O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态； 操作系统收到请求后，进一步将 I&#x2F;O 请求发送 DMA，然后让 CPU 执行其他任务； DMA 进一步将 I&#x2F;O 请求发送给磁盘； 磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满； DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务； 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU； CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回； 零拷贝传统文件传输服务端传送文件，一般是从磁盘上读取文件，然后通过网络协议发送给客户端。方法:read(file, tmp_buf, len);write(socket, tmp_buf, len); 期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。 零拷贝零拷贝技术实现的方式通常有 2 种： mmap + write sendfile mmap + writeread() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。这样减少了一次数据拷贝 但是远远不够。 sendfile它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。 如果网卡支持 SG-DMA，我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。 你可以在你的 Linux 系统通过下面这个命令，查看网卡是否支持 scatter-gather 特性： 12$ ethtool -k eth0 | grep scatter-gatherscatter-gather: on 这样sendfile系统调用发生了变化 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里； 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝； 这就是所谓的零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。 PageCache读取内存的速度比直接读取磁盘的速度要快很多很多，DMA技术便是将磁盘中的数据拷贝到内存中。内核缓冲区实际上就是PageCache。由于内存空间很小，一次只能从磁盘中拷贝很小一部分数据到内存。通常程序运行具有局限性，刚被访问的数据在短时间内再次被访问的概率很高，所以PageCache缓存着最近被访问的数据，当空间不足时淘汰最久未被访问的数据。 PageCache还具有预读功能，read方法一次只会读取32字节，但是内核会多读取后面32字节的内容，如果后32字节再被淘汰之前访问到了就大大降低了成本。 Select poll epollSocketSocket 的中文名叫作插口,双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候，都通过这个“口子”。这样一看，是不是觉得很像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。 服务端首先调用 socket() 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口。 绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，此时对应 TCP 状态图中的 listen，如果我们要判定服务器中一个网络程序有没有启动，可以通过 netstat 命令查看对应的端口号是否有被监听。 服务端进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。 那客户端是怎么发起连接的呢？客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。 在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列： 一个是「还没完全建立」连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握手的连接，此时服务端处于 syn_rcvd 的状态； 一个是「已经建立」连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握手的连接，此时服务端处于 established 状态； 当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。 注意，监听的 Socket 和真正用来传数据的 Socket 是两个：一个叫作监听 Socket；一个叫作已连接 Socket； 基于 Linux 一切皆文件的理念，在内核中 Socket 也是以「文件」的形式存在的，也是有对应的文件描述符。 I&#x2F;O多路复用为每一个请求分配一个进程&#x2F;线程是不现实的，一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用。 我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。 select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。 select&#x2F;pollselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。select使用的是数组表示文件描述符集合，以轮询的方式获取产生事件的socket。poll 不再用 数组 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。 epollepoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字。epoll使用事件驱动机制,内核中维护了一个链表记录有事件发生的socket。当某个socket有事件发生了，内核就会通过回调函数将其加入到就绪事件列表中。用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数。 ReactorReactor 模式也叫 Dispatcher 模式, 即** I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程**。Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下： Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件； 处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；","categories":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"浅析nacos源码一 服务注册","slug":"浅析nacos源码一 服务注册","date":"2023-07-07T09:29:10.792Z","updated":"2023-07-07T13:17:35.881Z","comments":true,"path":"2023/07/07/浅析nacos源码一 服务注册/","link":"","permalink":"http://example.com/2023/07/07/%E6%B5%85%E6%9E%90nacos%E6%BA%90%E7%A0%81%E4%B8%80%20%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C/","excerpt":"","text":"源码浅析第一篇 从nacos开始！ nacos基本架构Nacos（全称为 “Naming and Configuration Service”）是一个开源的分布式配置和服务发现平台，由阿里巴巴开源社区开发和维护。它提供了服务注册、发现和配置管理等功能，使得构建和管理微服务架构变得更加便捷。看一下官网给的架构图 和 一些基本概念服务注册中心 (Service Registry)服务注册中心，它是服务，其实例及元数据的数据库。服务实例在启动时注册到服务注册表，并在关闭时注销。服务和路由器的客户端查询服务注册表以查找服务的可用实例。服务注册中心可能会调用服务实例的健康检查 API 来验证它是否能够处理请求。注册表结构服务元数据 (Service Metadata)服务元数据是指包括服务端点(endpoints)、服务标签、服务版本号、服务实例权重、路由规则、安全策略等描述服务的数据。服务提供方 (Service Provider)是指提供可复用和可调用服务的应用方。服务消费方 (Service Consumer)是指会发起对某个服务调用的应用方。 服务注册Springcloud提供了一套服务自动注册的机制，其实就是三个接口，市面上的注册中心都会实现这三个接口 Registration服务实例数据封装可以看到服务实例一般包含以下一些属性nacos中的实现 NacosRegistration ServiceRegistry这个接口包含了服务注册相关的一些方法，服务实例都是通过register方法注册到注册中心的。 nacos中的实现 AutoServiceRegistration服务自动注册的入口看他的一个抽象实现:监听了WebServerInitializedEvent事件。WebServerInitializedEvent这个事件是SpringBoot在项目启动时，当诸如tomcat这类Web服务启动之后就会发布。所以服务实例在启动的时候就会监听到这个事件，然后进行服务注册。 **AbstractAutoServiceRegistration类中 bind方法就是监听了这个事件 **因此当服务启动的时候 便会自动注册当注册中心 start() register()注册的内容便是前面说的NacosRegistration而serviceRegistry就是上面提到的NacosServiceRegistryRegistration会转换成Instance有一些参数是来自于nacosDiscoveryProperties 就可以通过nacos的配置去修改 例如Ephemeral这里后面会用到 其默认值是true registerInstance()registerInstance(serviceId, group, instance) 服务注册到注册中心的核心方法先补充一个自动配置类NacosServiceRegistryAutoConfiguration 将上面说的三个类加载到了spring容器中 NamingService先看一下他的调用者NamingServiceNamingService里面有很多实例相关的方法 NacosServiceManager而NamingService通过NacosServiceManager创建NacosServiceManager 中有两个重要的service NamingService ** 和 NamingMaintainService ** 和一个NacosDiscoveryProperties 回到registerInstance()serverProxy就是NamingProxy NamingProxyNamingProxy是用于处理服务注册、发现和订阅等操作的代理类。它负责与Nacos Server进行通信，并执行服务注册、发现和订阅等操作的网络请求。所以这里会向注册中心发起一个注册请求 registerService前面是组装请求参数。reqApi里面有个callserver方法 向nacos服务器发起了一个post请求 地址是nacosUrlInstance 发起请求之后 就是nacos服务端的事情了 可以通过下面地址下载源码 文章使用的是1.4版本nacos源码地址 https://github.com/alibaba/nacos nacos服务端对外开发了很多API接口 文档地址如下地址:[https://nacos.io/zh-cn/docs/v2/guide/user/open-api.html](https://nacos.io/zh-cn/docs/v2/guide/user/open-api.html) &#x2F;instance接口InstanceController里面都是nacos对外提供的API地址我们在其中找到这个instance接口 ServiceManager.ServiceManager就是Nacos中管理服务、实例信息的核心API，其中就包含Nacos的服务注册表 registerInstance() createEmptyService方法createServiceIfAbsent初始了一个service 设置了namespaceId这些基本参数。看getService方法这里就能看出来 服务实例都是存到serviceMap中的 key为namespaceId value是一个以ServiceName为key 具体服务实例为value的map 可以回去看在客户端调用那里 serviceName其实是 GroupName@@ServiceName putServiceAndInit再看putServiceAndInit方法putService就是讲初始化好的service放到map中init方法有点像是初始化健康检查 后面再看先注意看后面两个listen方法 他们只有ephemeral不一样一个是Ephemeral 一个是Persistent Ephemeral和Persistent Persistent（持久化）：当服务实例以持久化方式注册到Nacos注册中心时，它的注册信息将会被持久存储。即使服务实例下线或重启，注册信息仍然会保留在注册中心中，直到显式注销。持久化注册适用于需要长期存在且稳定的服务实例，例如基础设施组件或长时间运行的服务。 Ephemeral（临时）：当服务实例以临时方式注册到Nacos注册中心时，它的注册信息将会与服务实例的生命周期绑定。一旦服务实例下线或重启，注册信息会被自动删除。临时注册适用于短期存在或频繁变化的服务实例，例如临时任务或动态扩缩容的实例。 前面客户端那边可以看到Ephemeral 是一个配置 可以根据你的要求通过修改配置文件来设置是持久还是临时节点 默认是临时节点 再看调用的service 这个service有很多实现类找到注入的地方 是用的consistencyDelegate后面也有类似的这种 就省略这个流程。 listen()判断是持久节点还是临时节点 由此看出来两个listen分别监听了持久和临时节点。listen方法就是往listeners 添加了一个RecordListener但是前面看到 传进来的参数一直是一个service 怎么这里变成RecordListener 因为service是RecordListener的一个实现类这里后续肯定会有地方 从这个map中取listener出来执行 实现一个监听的机制。 addInstance()addIpAddresses()返回的是当前服务对应的所有实例列表。实际情况一个服务一般都会有多个实例，他们的namespaceId、groupName、serviceName 都是相同的 因此如果当多实例同时注册的时候 需要一个并发控制。 put()DelegateConsistencyServiceImpl类下我们看临时节点的流程 下面是EphemeralConsistencyService的一个实现类DistroConsistencyServiceImpl onput()前面是将当前实例数据存到dataStore中 再次注意 这里的value是服务的一个实例列表 可能是多个实例 DataStore存储了服务实例的一些数据 Notifier.addTask()Notifier是当前DistroConsistencyServiceImpl的一个内部类action是change key是namespace+serviceNametasks是一个阻塞队列 而services的作用就是当action是change的时候 放进Map 可能是为了一个并发控制？用意不明。 后续是将当前实例对应的一个key和对应的操作封装成一个pair放到tasks阻塞队列中到此registerInstance方法就走完了当然 看到阻塞队列 就会想到 肯定有一处代码是从阻塞队列中取出任务来执行，Notifier又是一个runnable我们直接看他的run方法 Notifier.run()这里就是从阻塞队列取出一个pair handle()这里services移除key 看起来就是保证change行为 高并发的时候只执行一次。然后自然是进入change这个分支 调用onChange方法listeners就是熟面孔了 前面的putServiceAndInit方法就是创建了listener 那时就说了后面有地方会取出来 实现一个监听机制。而dataStore在前面就是存放了实例列表数据。看下dataStore的结果 Service.onChange()listener有多个实现而我们之前在putServiceAndInit方法中 我们是将service作为一个listener放进了map中 所以自然是看service的实现咯先是对实例的权重做一个修正 updateIPs()没截完 还有一段 Cluster.updateIps()updateIps是Cluster类下的个方法 Cluster是代表集群的一个实体这里有一个copyonwrite的机制 实现了一定程度上的读写分离 在服务写入的过程中 写操作是操作一个副本，当写操作完成了再将数据更新到原来的数据上 当多个服务发现的请求过来时 写操作不会影响到读操作 实现了对注册表的一个并发读写的功能。并且写的过程是通过阻塞队列 控制一次只执行一个写请求 。(能看到这些操作都是在**Notifier.run()**方法中执行的)综上可以看出一个关系链 Service-Cluster-Instanceservice中有一个Map&lt;String, Cluster&gt; clusterMap Cluster中有两个Set 分别是持久和临时节点 而我们在接口最初提到了ServiceManager中有一个注册表看到存放的是一个serviceMap由此一个清晰的关系图就浮现出来了 服务注册表的结构也就出来了但是其实可以看到 最后并没有将实例数据更新到ServiceMap上 再后面的源码分析中 应该会出现。 cluster.updateIps方法后面还有一个重要方法getPushService().serviceChanged(this); serviceChanged()这里主要就是发布一个ServiceChangeEvent事件到此run方法也结束了 接下来找到监听事件的地方 大概就是在pushservice中 因为看到pushservice实现了 ApplicationListener具体的实现 我们后面再看 以上就是nacos服务注册的一个大致流程了","categories":[{"name":"源码","slug":"源码","permalink":"http://example.com/categories/%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"}]},{"title":"Java并发","slug":"Java并发","date":"2023-06-26T02:24:54.879Z","updated":"2023-07-07T13:33:47.680Z","comments":true,"path":"2023/06/26/Java并发/","link":"","permalink":"http://example.com/2023/06/26/Java%E5%B9%B6%E5%8F%91/","excerpt":"","text":"# disruptor # A进程和线程 ## 进程 我们编写的代码只是⼀个存储在硬盘的静态⽂件，通过编译后就会⽣成⼆进制可执行文件，当我们运⾏这个可执⾏⽂件后，它会被装载到内存中，接着 CPU 会执⾏程序中的每⼀条指令，那么这个运⾏中的程序，就被称为「进程」（Process）。 进程的状态 NULL -&gt; 创建状态：⼀个新进程被创建时的第⼀个状态； 创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，⼀切就绪准备运⾏时，变为就绪状态，这个过程是很快的； 就绪态 -&gt; 运⾏状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运⾏该进程； 运⾏状态 -&gt; 结束状态：当进程已经运⾏完成或出错时，会被操作系统作结束状态处理； 运⾏状态 -&gt; 就绪状态：处于运⾏状态的进程在运⾏过程中，由于分配给它的运⾏时间⽚⽤完，操作系统会把该进程变为就绪态，接着从就绪态选中另外⼀个进程运⾏； 运⾏状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件； 阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态； 如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占⽤着物理内存就⼀种浪费物理内存的⾏为。所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运⾏ 的时候，再从硬盘换⼊到物理内存。 那么，就需要⼀个新的状态，来描述进程没有占⽤实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不⼀样，阻塞状态是等待某个事件的返回。另外，挂起状态可以分为两种： 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏ 导致进程挂起的原因不只是因为进程所使⽤的内存空间不在物理内存，还包括如下情况： 通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程。 ⽤户希望挂起⼀个程序的执⾏，⽐如在 Linux 中⽤ Ctrl+Z 挂起进程； 进程的控制结构在操作系统中，是⽤进程控制块（process control block，PCB）数据结构来描述进程的。 PCB 是进程存在的唯⼀标识，这意味着⼀个进程的存在，必然会有⼀个 PCB，如果进程消失了，那么PCB 也会随之消失。 PCB包含的信息: 进程描述信息： 进程标识符：标识各个进程，每个进程都有⼀个并且唯⼀的标识符； ⽤户标识符：进程归属的⽤户，⽤户标识符主要为共享和保护服务； 进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级； 资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I&#x2F;O 设备信息。 CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程 重新执⾏时，能从断点处继续执⾏。 PCB的组织形式通常是通过链表的⽅式进⾏组织，把具有相同状态的进程链在⼀起，组成各种队列。⽐如： 将所有处于就绪状态的进程链在⼀起，称为就绪队列； 把所有因等待某事件⽽处于等待状态的进程链在⼀起就组成各种阻塞队列； 另外，对于运⾏队列在单核 CPU 系统中则只有⼀个运⾏指针了，因为单核 CPU 在某个时间，只能运 ⾏⼀个程序。除了链接的组织⽅式，还有索引⽅式，它的⼯作原理：将同⼀状态的进程组织在⼀个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。⼀般会选择链表，因为可能⾯临进程创建，销毁等调度导致进程状态发⽣变化，所以链表能够更加灵活的插⼊和删除。 线程操作 创建进程操作系统允许⼀个进程创建另⼀个进程，⽽且允许⼦进程继承⽗进程所拥有的资源，当⼦进程被终⽌时，其在⽗进程处继承的资源应当还给⽗进程。同时，终⽌⽗进程时同时也会终⽌其所有的⼦进程。 创建进程的过程如下： 为新进程分配⼀个唯⼀的进程标识号，并申请⼀个空⽩的 PCB，PCB 是有限的，若申请失败则创建 失败； 为进程分配资源，此处如果资源不⾜，进程就会进⼊等待状态，以等待资源； 初始化 PCB； 如果进程的调度队列能够接纳新进程，那就将进程插⼊到就绪队列，等待被调度运⾏。 终止进程进程可以有 3 种终⽌⽅式：正常结束、异常结束以及外界⼲预（信号 kill 掉）。终⽌进程的过程如下： 查找需要终⽌的进程的 PCB； 如果处于执⾏状态，则⽴即终⽌该进程的执⾏，然后将 CPU 资源分配给其他进程； 如果其还有⼦进程，则应将其所有⼦进程终⽌； 将该进程所拥有的全部资源都归还给⽗进程或操作系统； 将其从 PCB 所在队列中删除。 阻塞进程当进程需要等待某⼀事件完成时，它可以调⽤阻塞语句把⾃⼰阻塞等待。⽽⼀旦被阻塞等待，它只能由另⼀个进程唤醒。阻塞进程的过程如下： 找到将要被阻塞进程标识号对应的 PCB； 如果该进程为运⾏状态，则保护其现场，将其状态转为阻塞状态，停⽌运⾏； 将该 PCB 插⼊到阻塞队列中去。 唤醒进程进程由「运⾏」转变为「阻塞」状态是由于进程必须等待某⼀事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒⾃⼰的。如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程⽤唤醒语句叫醒它。唤醒进程的过程如下： 在该事件的阻塞队列中找到相应进程的 PCB； 将其从阻塞队列中移出，并置其状态为就绪状态； 把该 PCB 插⼊到就绪队列中，等待调度程序调度； 进程的阻塞和唤醒是⼀对功能相反的语句，如果某个进程调用了阻塞语句，则必有⼀个与之对应的唤醒语 句。 进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执⾏，那么这个⼀个进程切换到另⼀个进程运⾏，称为进程的上下⽂切换。 大多数操作系统都是多任务，通常⽀持⼤于 CPU 数量的任务同时运⾏。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运⾏的错觉。 任务是交给 CPU 运⾏的，那么在每个任务运⾏前，CPU 需要知道任务从哪⾥加载，⼜从哪⾥开始运⾏。 所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。 程序计数器则是⽤来存储 CPU 正在执⾏的指令位置、或者即将执⾏的下⼀条指令位置。 CPU 寄存器和程序计数是 CPU 在运⾏任何任务前，所必须依赖的环境，这些环境就叫做 CPU上下文。 CPU 上下文切换就是先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务。系统内核会存储保持下来的上下⽂信息，当此任务再次被分配给 CPU 运⾏时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 线程线程是进程当中的⼀条执⾏流程。 同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独立的。 线程与进程的⽐较 进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位； 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执⾏的时间和空间开销。 线程的上下⽂切换所谓操作系统的任务调度，实际上的调度对象是线程，⽽进程只是给线程提供了虚拟内存、全局变量等资源。 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样； 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不 动，只需要切换线程的私有数据、寄存器等不共享的数据。 创建和运行线程 Thread12345678910// 构造方法的参数是给线程指定名字，推荐Thread t1 = new Thread(&quot;t1&quot;) &#123; @Override // run 方法内实现了要执行的任务 public void run() &#123; log.debug(&quot;hello&quot;); &#125;&#125;;t1.start(); Runnable123456789101112131415161718// 创建任务对象Runnable task2 = new Runnable() &#123; @Override public void run() &#123; log.debug(&quot;hello&quot;); &#125;&#125;;// 参数1 是任务对象; 参数2 是线程名字，推荐Thread t2 = new Thread(task2, &quot;t2&quot;);t2.start(); // 创建任务对象Runnable task2 = () -&gt; log.debug(&quot;hello&quot;);// 参数1 是任务对象; 参数2 是线程名字，推荐Thread t2 = new Thread(task2, &quot;t2&quot;);t2.start(); runnable底层就是调用了thread的run方法。用 Runnable 更容易与线程池等高级 API 配合用 Runnable 让任务类脱离了 Thread 继承体系，更灵活 Callable1234567891011FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;()&#123; @0verride public Integer call() throws Exception &#123; Log.debug( &quot;running...&quot;); Thread.sleep( millis: 2000);return 100; &#125; &#125;);Thread t1 = new Thread(task,name: &quot;t1&quot;);t1.start();log.debug(&quot;0&quot;, task.get()); 常见方法 start和run直接调用 run 是在主线程中执行了 run，没有启动新的线程使用 start 是启动新的线程，通过新的线程间接执行 run 中的代码 sleep和yieldsleep: 调用 sleep 会让当前线程从 Running 进入 Timed Waiting 状态（阻塞） 其它线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep 方法会抛出 InterruptedException 睡眠结束后的线程未必会立刻得到执行 建议用 TimeUnit 的 sleep 代替 Thread 的 sleep 来获得更好的可读性 yield:1. 调用 yield 会让当前线程从 Running 进入 Runnable 就绪状态，然后调度执行其它线程2. 具体的实现依赖于操作系统的任务调度器 interrupt()interrupt()并不能真正的停止线程，只是更换了线程状态标志。线程还会继续执行 123456789101112MyThread7 thread = new MyThread7(); thread.start();System.out.println(thread.getName() + &quot;线程的中断状态：&quot; + thread.isInterrupted());thread.interrupt(); // 由主线程中断了一个子线程System.out.println(thread.getName() + &quot;线程的中断状态：&quot; + thread.isInterrupted());//结果Thread-0线程的中断状态：falseThread-0线程的中断状态：true 在Core Java中有这样一句话：&quot;没有任何语言方面的需求要求一个被中断的程序应该终止。中断一个线程只是为了引起该线程的注意，被中断线程可以决定如何应对中断 &quot;。这句话启发了我们如何正确的中断一个线程，中断一个线程的本质就是中断run()方法的执行，也就是说run()不再执行后，这个线程就结束了。所以，通过中断状态标志位来控制run()方法中逻辑代码的运行，就可以很好的保证线程的中断。 12345678910111213public void run()&#123; try&#123; //这里的while循环不断的检查中断状态，一旦状态转为true， //也就是执行了interrupt方法，那么逻辑代码不再执行。 while(!Thread.currentThread().isInterrupted() &amp;&amp; more work to do) &#123; // do more work; &#125; &#125; catch(InterruptedException e) &#123; // thread was interrupted during sleep or wait &#125; finally &#123; // cleanup, if required &#125; &#125; 使用线程对象的stop()方法停止线程stop方法会真正杀死线程，如果这时线程锁住了共享资源，那么当它被杀死后就再也没有机会释放锁，其它线程将永远无法获取锁。所以一般的lock()方法 无法响应中断，而像lockInterruptibly()、tryLock()等方法就会检测线程中断状态，一旦发现线程处于旦中断状态则立即抛出** InterruptedException** 那阻塞状态的线程如果终止呢? 答案 抛出异常！ 我们在sleep方法中看到过，它抛出了一个InterruptedException，当一个线程使用了sleep方法（wait、join）处于阻塞状态时，再使用interrupt就会触发sleep方法抛出InterruptedException异常（实际上是给阻塞的线程发出中断信号，阻塞线程检查到中断标识,就会抛出异常），进而导致线程中断。 打断 sleep 的线程, 会清空打断状态。(将标志位改为false) interrupted()方法作用是测试当前线程是否已经中断，线程的中断状态也是由该方法清除 123456789Thread.currentThread().interrupt();System.out.println(Thread.currentThread().getName() + &quot;线程的中断状态：&quot; + Thread.currentThread().interrupted());System.out.println(Thread.currentThread().getName() + &quot;线程的中断状态：&quot; + Thread.currentThread().interrupted());//结果main线程的中断状态：truemain线程的中断状态：false 主线程被打断，使用interrupted()方法查看中断状态，发现标志位改为了true；再次使用interrupted()查看中断状态，发现标志位改为false。在第一次使用interrupted()方法时，它返回标志位，同时清除标志位（置为false），导致下一次的返回值变为false。所以interrupted()方法有清除标志位的功能 isInterrupted()测试此线程是否已被中断。线程的中断状态不受此方法的影响 Join等待调用join的线程结束，才继续向下运行。 wait notify Owner线程发现条件不满足，调用wait方法，即可进入WaitSet变为WAITING状态 BLOCKED和WAITING的线程都处于阻塞状态，不占用CPU时间片 BLOCKED线程会在Owner线程释放锁时唤醒 WAITNG线程会在Owner线程调用notify或notifyAll 时唤醒，但唤醒后并不意味者立刻获得锁，仍需进入EntryList重新竞争 123456789101112synchronized (lock) &#123; while(条件不成立)&#123; lock.wait( ); &#125; //干活&#125;另一个线程synchronized (lock) &#123; lock.notifyAll( );&#125; sleep和wait的区别 sleep是Thread方法，而wait是Object的方法 sleep不需要强制和synchronized配合使用，但wait需要和synchronized一起用 sleep在睡眠的同时，不会释放对象锁的，但wait在等待的时候会释放对象锁。 park unpark它们是LockSupport类中的方法 12345//暂停当前线程LockSupport.park( );//恢复某个线程的运行LockSupport.unpark(暂停线程对象) 与Object的 wait &amp; notify相比 wait，notify和notifyAll必须配合Object Monitor一起使用，而park，unpark不必 park &amp; unpark是以线程为单位来【阻塞】和【唤醒】线程，而notify 只能随机唤醒一个等待线程，notifyAll是唤醒所有等待线程，就不那么【精确】 park &amp; unpark可以先unpark，而wait &amp; notify 不能先notify 原理:调用park就是要看需不需要停下来歇息 如果备用干粮耗尽，那么钻进帐篷歇息 如果备用干粮充足，那么不需停留，继续前进 调用unpark，就好比令干粮充足 如果这时线程还在帐篷，就唤醒让他继续前进 如果这时线程还在运行，那么下次他调用park时，仅是消耗掉备用干粮，不需停留继续刖进 因为背包空间有限，多次调用unpark仅会补充一份备用干粮 不推荐的方法这些方法已过时，容易破坏同步代码块，造成线程死锁 stop() 停止线程运行 suspend() 挂起（暂停）线程运行 resume() 恢复线程运行 守护线程Java 进程需要等待所有线程都运行结束，才会结束。有一种特殊的线程叫做守护线程，只要其它非守护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束。 monitor每个Java对象都可以关联一个Monitor对象，如果使用synchronized给对象上锁（重量级）之后，该对象头的Mark Word 中就被设置指向Monitor对象的指针。 刚开始Monitor中Owner为null 当Thread-2 执行synchronized(obj)就会将Monitor的所有者Owner置为Thread-2，Monitor中只能有一个Owner 在Thread-2上锁的过程中，如果Thread-3，Thread-4，Thread-5也来执行synchronized(obj)，就会进入EntryList BLOCKED Thread-2执行完同步代码块的内容，然后唤醒EntryList 中等待的线程来竞争锁，竞争的时是非公平的 图中 WaitSet中的Thread-0，Thread-1是之前获得过锁，调用了wait()方法的线程。 一个对象对应一个monitor 关闭线程池 JUC reetrantLock相对于synchronized它具备如下特点 可中断 可以设置超时时间 可以设置为公平锁 支持多个条件变量 和synchronized一样，都支持可重入 不公平锁 12345678910//获取锁reentrantLock .lock( );try &#123; //临界区&#125;finally &#123; //释放锁reentrantLock.unlock( );&#125; Condition 条件变量ReentrantLock的条件变量比 synchronized强大之处在于，它是支持多个条件变量的，这就好比 synchronized是那些不满足条件的线程都在一间休息室等消息，而ReentrantLock支持多间休息室，有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤醒。 使用流程 await 前需要获得锁 await 执行后，会释放锁，进入conditionObject 等待 await的线程被唤醒（回打断、或超时）取重新竞争lock锁 竞争 lock 锁成功后，从await后继续执行 对应唤醒方法 signal(); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263static ReentrantLock lock = new ReentrantLock();static Condition waitCigaretteQueue = lock.newCondition();static Condition waitbreakfastQueue = lock.newCondition();static volatile boolean hasCigrette = false;static volatile boolean hasBreakfast = false;public static void main(String[] args) &#123; new Thread(() -&gt; &#123; try &#123; lock.lock(); while (!hasCigrette) &#123; try &#123; waitCigaretteQueue.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; log.debug(&quot;等到了它的烟&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;).start(); new Thread(() -&gt; &#123; try &#123; lock.lock(); while (!hasBreakfast) &#123; try &#123; waitbreakfastQueue.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; log.debug(&quot;等到了它的早餐&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;).start(); sleep(1); sendBreakfast(); sleep(1); sendCigarette();&#125;private static void sendCigarette() &#123; lock.lock(); try &#123; log.debug(&quot;送烟来了&quot;); hasCigrette = true; waitCigaretteQueue.signal(); &#125; finally &#123; lock.unlock(); &#125;&#125;private static void sendBreakfast() &#123; lock.lock(); try &#123; log.debug(&quot;送早餐来了&quot;); hasBreakfast = true; waitbreakfastQueue.signal(); &#125; finally &#123; lock.unlock(); &#125;&#125; 线程池123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260package cn.itcast.n8;import lombok.extern.slf4j.Slf4j;import org.springframework.core.log.LogDelegateFactory;import java.util.ArrayDeque;import java.util.Deque;import java.util.HashSet;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;@Slf4j(topic = &quot;c.TestPool&quot;)public class TestPool &#123; public static void main(String[] args) &#123; ThreadPool threadPool = new ThreadPool(1, 1000, TimeUnit.MILLISECONDS, 1, (queue, task)-&gt;&#123; // 1. 死等// queue.put(task); // 2) 带超时等待// queue.offer(task, 1500, TimeUnit.MILLISECONDS); // 3) 让调用者放弃任务执行// log.debug(&quot;放弃&#123;&#125;&quot;, task); // 4) 让调用者抛出异常// throw new RuntimeException(&quot;任务执行失败 &quot; + task);· // 5) 让调用者自己执行任务 task.run(); &#125;); for (int i = 0; i &lt; 4; i++) &#123; int j = i; threadPool.execute(() -&gt; &#123; try &#123; Thread.sleep(1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace();reject &#125; log.debug(&quot;&#123;&#125;&quot;, j); &#125;); &#125; &#125;&#125;@FunctionalInterface // 拒绝策略interface RejectPolicy&lt;T&gt; &#123; void reject(BlockingQueue&lt;T&gt; queue, T task);&#125;@Slf4j(topic = &quot;c.ThreadPool&quot;)class ThreadPool &#123; // 任务队列 private BlockingQueue&lt;Runnable&gt; taskQueue; // 线程集合 private HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;(); // 核心线程数 private int coreSize; // 获取任务时的超时时间 private long timeout; private TimeUnit timeUnit; private RejectPolicy&lt;Runnable&gt; rejectPolicy; // 执行任务 public void execute(Runnable task) &#123; // 当任务数没有超过 coreSize 时，直接交给 worker 对象执行 // 如果任务数超过 coreSize 时，加入任务队列暂存 synchronized (workers) &#123; if(workers.size() &lt; coreSize) &#123; Worker worker = new Worker(task); log.debug(&quot;新增 worker&#123;&#125;, &#123;&#125;&quot;, worker, task); workers.add(worker); worker.start(); &#125; else &#123;// taskQueue.put(task); // 1) 死等 // 2) 带超时等待 // 3) 让调用者放弃任务执行 // 4) 让调用者抛出异常 // 5) 让调用者自己执行任务 taskQueue.tryPut(rejectPolicy, task); &#125; &#125; &#125; public ThreadPool(int coreSize, long timeout, TimeUnit timeUnit, int queueCapcity, RejectPolicy&lt;Runnable&gt; rejectPolicy) &#123; this.coreSize = coreSize; this.timeout = timeout; this.timeUnit = timeUnit; this.taskQueue = new BlockingQueue&lt;&gt;(queueCapcity); this.rejectPolicy = rejectPolicy; &#125; class Worker extends Thread&#123; private Runnable task; public Worker(Runnable task) &#123; this.task = task; &#125; @Override public void run() &#123; // 执行任务 // 1) 当 task 不为空，执行任务 // 2) 当 task 执行完毕，再接着从任务队列获取任务并执行// while(task != null || (task = taskQueue.take()) != null) &#123; while(task != null || (task = taskQueue.poll(timeout, timeUnit)) != null) &#123; try &#123; log.debug(&quot;正在执行...&#123;&#125;&quot;, task); task.run(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; task = null; &#125; &#125; synchronized (workers) &#123; log.debug(&quot;worker 被移除&#123;&#125;&quot;, this); workers.remove(this); &#125; &#125; &#125;&#125;@Slf4j(topic = &quot;c.BlockingQueue&quot;)class BlockingQueue&lt;T&gt; &#123; // 1. 任务队列 private Deque&lt;T&gt; queue = new ArrayDeque&lt;&gt;(); // 2. 锁 private ReentrantLock lock = new ReentrantLock(); // 3. 生产者条件变量 private Condition fullWaitSet = lock.newCondition(); // 4. 消费者条件变量 private Condition emptyWaitSet = lock.newCondition(); // 5. 容量 private int capcity; public BlockingQueue(int capcity) &#123; this.capcity = capcity; &#125; // 带超时阻塞获取 public T poll(long timeout, TimeUnit unit) &#123; lock.lock(); try &#123; // 将 timeout 统一转换为 纳秒 long nanos = unit.toNanos(timeout); while (queue.isEmpty()) &#123; try &#123; // 返回值是剩余时间 if (nanos &lt;= 0) &#123; return null; &#125; nanos = emptyWaitSet.awaitNanos(nanos); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; T t = queue.removeFirst(); fullWaitSet.signal(); return t; &#125; finally &#123; lock.unlock(); &#125; &#125; // 阻塞获取 public T take() &#123; lock.lock(); try &#123; while (queue.isEmpty()) &#123; try &#123; emptyWaitSet.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; T t = queue.removeFirst(); fullWaitSet.signal(); return t; &#125; finally &#123; lock.unlock(); &#125; &#125; // 阻塞添加 public void put(T task) &#123; lock.lock(); try &#123; while (queue.size() == capcity) &#123; try &#123; log.debug(&quot;等待加入任务队列 &#123;&#125; ...&quot;, task); fullWaitSet.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task); queue.addLast(task); emptyWaitSet.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; // 带超时时间阻塞添加 public boolean offer(T task, long timeout, TimeUnit timeUnit) &#123; lock.lock(); try &#123; long nanos = timeUnit.toNanos(timeout); while (queue.size() == capcity) &#123; try &#123; if(nanos &lt;= 0) &#123; return false; &#125; log.debug(&quot;等待加入任务队列 &#123;&#125; ...&quot;, task); nanos = fullWaitSet.awaitNanos(nanos); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task); queue.addLast(task); emptyWaitSet.signal(); return true; &#125; finally &#123; lock.unlock(); &#125; &#125; public int size() &#123; lock.lock(); try &#123; return queue.size(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void tryPut(RejectPolicy&lt;T&gt; rejectPolicy, T task) &#123; lock.lock(); try &#123; // 判断队列是否满 if(queue.size() == capcity) &#123; rejectPolicy.reject(this, task); &#125; else &#123; // 有空闲 log.debug(&quot;加入任务队列 &#123;&#125;&quot;, task); queue.addLast(task); emptyWaitSet.signal(); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; ThreadPoolExecutor 线程池状态ThreadPoolExecutor使用int的高3位来表示状态，低29位表示线程数量 构造方法1234567public ThreadPoolExecutor(int corePoolSize, (核心线程数) int maximumPoolSize, (最大线程数) long keepAliveTime,(生存时间) TimeUnit unit,(生存时间-时间单位) BlockingQueue&lt;Runnable&gt; workQueue,(阻塞队列) ThreadFactory threadFactory,(线程工厂) RejectedExecutionHandler handler) (拒绝策略) 当核心线程和阻塞队列都被占满时，就会先创建救急线程来执行任务，如果救急线程都不够了，才会使用拒绝策略。救急线程数&#x3D;maximumPoolSize-corePoolSize；当救急线程空闲下来，存活的时间&#x3D;keepAliveTime； 拒绝策略： AbortPolicy让调用者抛出RejectedExecutionException异常，这是默认策略 CallerRunsPolicy让调用者运行任务 DiscardPolicy 放弃本次任务 DiscardOldestPolicy放弃队列中最早的任务，本任务取而代之。 其他框架拒绝策略实现 Dubbo的实现，在抛出RejectedExecutionException异常之前会记录日志,并dump线程栈信息，方便定位问题 Netty 的实现，是创建一个新线程来执行任务 ActiveMQ的实现，带超时等待（60s）尝试放入队列，类似我们之前自定义的拒绝策略 PinPoint的实现，它使用了一个拒绝策略链，会逐一尝试策略链中每种拒绝策略 工厂方法创建线程池 newFixedThreadPool123456public static ExecutorService newFixedThreadPool(int nThreads) return new ThreadPoolExecutor(nThreads, nThreads, 0L,TimeUnit.MILLISECONDs, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 核心线程数&#x3D;&#x3D;最大线程数（没有救急线程被创建)，因此也无需超时时间阻塞队列是无界的，可以放任意数量的任务 newCacheThreadPool123456public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0,Integer.MAX_VALUE, 60L,TimeUnit.SECONDs, new SynchronousQueue&lt;Runnable&gt;());&#125; 核心线程数是0，最大线程数是Integer.MAX_VALUE，救急线程的空闲生存时间是60s，意味着 全部都是救急线程（60s后可以回收) 救急线程可以无限创建 队列采用了SynchronousQueue实现特点是，它没有容量，没有线程来取是放不进去的(一手交钱、一手交货) newSingleThreadExecutor1234567public static Executorservice newSingleThreadExecutor() &#123;return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1,1, 0L,TimeUnit.MILLISECONDs, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会新建一个线程，保证池的正常工作 Executors.newSingleThreadExecutor()线程个数始终为1，不能修改 FinalizableDelegatedExecutorService应用的是装饰器模式，只对外暴露了ExecutorService接口，因此不能调用ThreadPoolExecutor 中特有的方法 Executors.newFixedThreadPool(1)初始时为1，以后还可以修改 对外暴露的是ThreadPoolExecutor对象，可以强转后调用setCorePoolSize等方法进行修改 Fork&#x2F;JoinFork&#x2F;Join是JDK1.7加入的新的线程池实现，它体现的是一种分治思想。适用于能够进行任务拆分的cpu密集型运算。 所谓的任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波那契数列、都可以用分治思想进行求解。 Fork&#x2F;Join在分治的基础上加入了多线程，可以把每个任务的分解和合并交给不同的线程来完成，进一步提升了运算效率。 Fork&#x2F;Join默认会创建与cpu核心数大小相同的线程池。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public static void main(String[] args) &#123; ForkJoinPool pool = new ForkJoinPool(4);// System.out.println(pool.invoke(new AddTask1(5))); System.out.println(pool.invoke(new AddTask3(1, 5))); &#125;&#125;//简单拆分 每次加法拆一个线程@Slf4j(topic = &quot;c.AddTask&quot;)class AddTask1 extends RecursiveTask&lt;Integer&gt; &#123; int n; public AddTask1(int n) &#123; this.n = n; &#125; @Override public String toString() &#123; return &quot;&#123;&quot; + n + &#x27;&#125;&#x27;; &#125; @Override protected Integer compute() &#123; if (n == 1) &#123; log.debug(&quot;join() &#123;&#125;&quot;, n); return n; &#125; AddTask1 t1 = new AddTask1(n - 1); //拆分 t1.fork(); log.debug(&quot;fork() &#123;&#125; + &#123;&#125;&quot;, n, t1); //join:得到这次拆分的结果 int result = n + t1.join(); log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, n, t1, result); return result; &#125;&#125;//二分法拆分@Slf4j(topic = &quot;c.AddTask&quot;)class AddTask3 extends RecursiveTask&lt;Integer&gt; &#123; int begin; int end; public AddTask3(int begin, int end) &#123; this.begin = begin; this.end = end; &#125; @Override public String toString() &#123; return &quot;&#123;&quot; + begin + &quot;,&quot; + end + &#x27;&#125;&#x27;; &#125; @Override protected Integer compute() &#123; if (begin == end) &#123; log.debug(&quot;join() &#123;&#125;&quot;, begin); return begin; &#125; if (end - begin == 1) &#123; log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, begin, end, end + begin); return end + begin; &#125; int mid = (end + begin) / 2; AddTask3 t1 = new AddTask3(begin, mid); t1.fork(); AddTask3 t2 = new AddTask3(mid + 1, end); t2.fork(); log.debug(&quot;fork() &#123;&#125; + &#123;&#125; = ?&quot;, t1, t2); int result = t1.join() + t2.join(); log.debug(&quot;join() &#123;&#125; + &#123;&#125; = &#123;&#125;&quot;, t1, t2, result); return result; &#125; AQS全称是AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架AQS使用一个violatile的int类型的成员变量state来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，将每条要抢占资源的线程封装成一个Node节点来完成锁的分配，通过CAS完成对state值的修改 AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore&#x2F;CountDownLatch）。 ReetrantLock之类的自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队&#x2F;唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返w回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 自定义同步器内部会有一个AbstractQueuedSynchronizer的子类对象sync来使用aqs的内部API完成锁相关的操作。 Node结点是对每一个等待获取资源的线程的封装，其包含了需要同步的线程本身及其等待状态，如是否被阻塞、是否等待唤醒、是否已经被取消等。变量waitStatus则表示当前Node结点的等待状态，共有5种取CANCELLED、SIGNAL、CONDITION、PROPAGATE、0。 CANCELLED(1)：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL(-1)：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL。 CONDITION(-2)：表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 PROPAGATE(-3)：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。 0：新结点入队时的默认状态12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 此方法是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响tryAcquire(int)：1234protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125;//AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现 reetrantLock原理1234567891011121314151617181920// sync是ReentrantLock的一个属性对象 aqs的子类public void lock() &#123; sync.lock();&#125; abstract static class Sync extends AbstractQueuedSynchronizer &#123; abstract void lock();//reetrantLock中有两个sync实现类 ...... &#125;//非公平锁static final class NonfairSync extends Sync &#123; final void lock() &#123; if (compareAndSetState(0, 1)) //设置aps中一个变量为当前线程，记录当前抢占到锁的线程 setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; &#125; 假如有三个线程ABC ,线程A首先拿到了锁，线程B执行lock方法时就会走到acquire方法 12345678//这是调用的sync父类-aqs的方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; selfInt errupt(); &#125; &#125; 可重入原理见代码 12345678910111213141516171819202122232425262728// 这里调用进入非公平锁的tryAcquire protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; // 具体代码在这里 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //若当前无其他线程抢占锁，则抢占；这里体现了非公平锁。 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果已获取锁的线程再调用lock()则state值+1，这里就是可重入的原理 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; // 都不是则返回false return false; &#125;//显然 此时应该返回false 就会走后面的判断//acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 先看 addwaiter方法 123456789101112131415161718192021 private Node addWaiter(Node mode) &#123; // 创建一个节点 mode Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 刚开始tail是null，如果tail有值了就将node插入队尾； if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 若队列为空，则插入节点 enq(node); return node; &#125;//如果队列中有节点，队尾就不会为空，就将当前节点作为尾节点，此时队列为空，走enq方法 12345678910111213141516private Node enq(final Node node) &#123; for (;;) &#123; // 死循环 Node t = tail; if (t == null) &#123; // 初始下tail为null，因此创建一个头节点 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t;// 第二次循环，队列不为空，就将该节点插入队尾 if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; enq插入节点是死循环:第一次循环，由于tail为空，他先创建一个空的node节点，作为头节点，此时waitStatus&#x3D;0，然后将head指向该头节点，并将tail指针也指向head;第二次循环，他将待插入node节点（线程B）的前置指针指向tail指向的节点（头节点），然后CAS将tail指向当前待插入节点（线程B），再让原来的tail指向的节点（头节点）的next域指向当前节点，这样就完成了节点（线程B）插入队尾，完成链式结构，跳出循环；此时head依然是虚拟头节点，tail指向刚插入的节点 现在就要进入前面acquire的AQS.acquireQueued(node, 1)方法了 1234567891011121314151617181920212223final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//获取节点的前置节点，线程B获取到的是头节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123;//由于线程A占用，尝试获取失败 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())// 线程B会进入这里 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 第一次循环：首先predecessor()取出的就是前置节点，p就是链表中的头节点，然后进入判断，当前确实是头节点，然后再次尝试tryAcquire()，由于线程A并没有释放锁，因此，只能进入shouldParkAfterFailedAcquire()方法； 1234567891011121314151617private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus;// 头节点的waitStatus=0 if (ws == Node.SIGNAL)// -1 return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL);// 将头节点的waitStatus设置成-1 &#125; return false; &#125;//AQS.shouldParkAfterFailedAcquire(头节点，当前节点)，由于头节点的waitStatus等于0，//因此这里最终将头节点的waitStatus设置成-1，并返回false； 然后进行第二次循环，再次进入shouldParkAfterFailedAcquire(),这一次由于ws&#x3D;-1，因此返回true，并进入parkAndCheckInterrupt()方法；这里会调用LockSupport.park()将线程挂起，此刻线程B就阻塞再这里了。 12345private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 接着线程C调用lock()方法省略前面的步骤，跳到addWaiter方法。此刻addWaiter()方法的执行和线程B就有区别了，因为CLH队列有节点了，他直接将创建好的Node插入队尾并返回； 12345678910111213141516171819private Node addWaiter(Node mode) &#123; // 创建一个节点 线程C Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 此时队列右节点，进入if if (pred != null) &#123; // 插入线程C节点到队尾并返回 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 线程C不走这里 enq(node); return node; &#125; 接着是acquireQueued()方法这里由于线程C的前置节点不是头节点，因此直接进入shouldParkAfterFailedAcquire()将线程B的状态改为-1；这里线程C把线程B节点的status改为了-1； 线程A调用unlock()方法 123456789101112131415161718192021222324252627282930// 执行ReentrantLock.unlock() public void unlock() &#123; sync.release(1); &#125;// AQS.release() public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125;// 执行ReentrantLock.tryRelease() protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; //c==0才会返回true 实现锁重入 free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125;//这里呢，线程A就先去获取AQS的state，并对应减去1个，并设置当前占有线程为null，//然后找到头节点去调用unparkSuccessor(head); 123456789101112131415161718192021private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus;// 头节点是-1 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0);// 头节点设置为0 Node s = node.next;// 线程B /* * 如果前驱放弃了，那就一直往前找，直到找到最近一个正常等待的状态，并排在它的后边。 * 注意：那些放弃的结点，由于被自己“加塞”到它们前边，它们相当于形成一个无引用链， * 稍后就会被保安大叔赶走了(GC回收)！ */ if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒线程B &#125;//此刻进入unparkSuccessor(头节点)中，他将头节点的状态从-1设置为0，然后唤醒线程B； 线程B唤醒后就会执行acquireQueued第三次循环第三次循环时，执行tryAcquire 如果此时又来了一个线程获取锁，就会和线程B竞争，看获取到。这就是非公平的体现。 123456789101112131415161718192021222324252627282930final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//获取节点的前置节点，线程B获取到的是头节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123;//目前锁无占用，进入此处 setHead(node); // 重新设置头节点 p.next = null; // help GC failed = false; return interrupted; // 被改为true &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())// 线程B从这里唤醒 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;// 修改头节点 private void setHead(Node node) &#123; head = node; node.thread = null; node.prev = null; &#125; 可打断原理不可打断模式在此模式下，即使它被打断，仍会驻留在AQS队列中，等获得锁后方能继续运行（是继续运行!只是打断标记被设置为true) 123456789101112131415161718192021222324252627282930313233343536373839404142434445final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt())// 线程B会进入这里 //线程在这里阻塞,如果外面调用打断方法会唤醒线程 看下面的方法 //就会将interrupted置为true,然后继续for循环 //后面的循环又会park住 //当之前获取到锁的线程释放锁，唤醒park // 此时下面的方法会返回false跳出if, 此时interrupted为true //正常没有打断的情况。parkAndCheckInterrupt返回的都是false就不会进入if语句 interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); //打断后 返回true但是线程中断标志位为false。返回true会执行后面的if语句, //如果不清除打断标记，那线程中断标志位就为true,park会失效，无法阻塞。 return Thread.interrupted();&#125;//这是调用的sync父类-aqs的方法public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; //被打断后 acquireQueued返回true 会执行selfInterrupt方法 执行中断 selfInterrupt(); &#125; &#125; 公平锁的原理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; // AQS 继承过来的方法, 方便阅读, 放在此处 public final void acquire(int arg) &#123; if ( !tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg) ) &#123; selfInterrupt(); &#125; &#125; // 与非公平锁主要区别在于 tryAcquire 方法的实现 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 先检查 AQS 队列中是否有前驱节点, 没有才去竞争 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125;else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; // h != t 时表示队列中有 Node return h != t &amp;&amp; ( // (s = h.next) == null 表示队列中还有没有老二 (s = h.next) == null || // 或者队列中老二线程不是此线程 s.thread != Thread.currentThread() ); &#125;&#125; 条件变量condition的实现原理每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject 12345678910111213ReentrantLock lock = new ReentrantLock();Condition condition = lock.newCondition();condition.await();public Condition newCondition() &#123; return sync.newCondition();&#125;final ConditionObject newCondition() &#123; //new ConditionObject()是aqs的方法 返回其内部的ConditionObject对象 是condition类的实现类 return new ConditionObject();&#125; ** 开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 流程 ** 1234567891011121314151617181920212223242526272829303132333435363738//aqs中ConditionObject对象对condition类await方法的实现 ConditionObject是aqs里面的一个子classpublic final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125;//调用addConditionWaiter方法 private Node addConditionWaiter() &#123; //firstWaiter lastWaiter 是条件队列ConditionObject首尾指针 Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; &#125;//创建新的 Node 状态为 -2（Node.CONDITION），关联 执行await方法的线程，加入等待队列尾部 接下来进入 AQS 的 fullyRelease 流程，释放同步器上的锁 1234567891011121314151617181920212223242526 final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125; &#125; public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125;//释放锁之后，唤起等待队列里的线程来竞争锁 假设thread-1竞争成功 接着 Thread-0就会park 阻塞 接下来看signal流程 1234567891011121314151617181920212223242526272829303132333435//将等待时间最长的线程（如果存在）从该条件的等待队列移动到拥有锁的等待队列public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); &#125;private void doSignal(Node first) &#123; do &#123; //将first移除条件队列 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; //transferForSignal将firrst转移到等待锁的队列 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125;final boolean transferForSignal(Node node) &#123; /* * cas设置当前节点的waitStauts为1 */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //加入队列 Node p = enq(node); int ws = p.waitStatus; //将前驱节点的状态改成-1 代表有责任唤醒下一个节点 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &#125; 假设Thread-1唤醒Thread-0 ReentrantReadWriteLock当读操作远远高于写操作时，这时候使用 读写锁 让 读-读 可以并发，提高性能。 类似于数据库中的 select …from … lock in share mode 123456789101112131415161718192021222324252627282930class DataContainer &#123; private Object data; private ReentrantReadWriteLock rw = new ReentrantReadWriteLock(); private ReentrantReadWriteLock.ReadLock r = rw.readLock(); private ReentrantReadWriteLock.WriteLock w = rw.writeLock(); public Object read() &#123; log.debug(&quot;获取读锁...&quot;); r.lock(); try &#123; log.debug(&quot;读取&quot;); sleep(1); return data; &#125; finally &#123; log.debug(&quot;释放读锁...&quot;); r.unlock(); &#125; &#125; public void write() &#123; log.debug(&quot;获取写锁...&quot;); w.lock(); try &#123; log.debug(&quot;写入&quot;); sleep(1); &#125; finally &#123; log.debug(&quot;释放写锁...&quot;); w.unlock(); &#125; &#125;&#125; 读锁不支持条件变量 重入时升级不支持：即持有读锁的情况下去获取写锁，会导致获取写锁永久等待 重入时降级支持：即持有写锁的情况下去获取读锁 原理读写锁用的是同一个sync锁(aqs的子类)，因此等待队列、state也用的同一个 现在假设有两个线程t1、t2，t1要加写锁，t2加读锁 l ) t1成功上锁，流程与ReentrantLock加锁相比没有特殊之处，不同是写锁状态占了state的低16位，而读锁使用的是state的高16位。 12345678910111213141516171819202122232425262728293031323334public void lock() &#123; sync.acquire(1);&#125; public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg))&#125;protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); //写锁 int w = exclusiveCount(c); if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;&#125; 2 ) t2执行r.lock，这时进入读锁的sync.acquireShared(1)流程，首先会进入tryAcquireShared流程。如果有写锁占据，那么tryAcquireShared返回-1表示失败 12345678public void lock() &#123; sync.acquireShared(1); &#125; public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; 12345678910111213141516171819202122232425262728293031323334 protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125;tryAcquireShared返回值表示:-1表示失败0表示成功，但后继节点不会继续唤醒正数表示成功，而且数值是还有几个后继节点需要唤醒，读写锁返回1这时tryAcquireShared返回-1 执行doAcquireShared方法 123456789101112131415161718192021222324252627private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 后续t3 r.lock,t4 w.lock这种状态下，假设又有t3加读锁和t4加写锁，这期间t1仍然持有锁，就变成了下面的样子t1.unlock() 123456789101112131415161718192021222324public void unlock() &#123; sync.releaseShared(1);&#125;public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; protected final boolean tryRelease(int releases) &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); setState(nextc); return free; &#125; 解锁之后 会再来一次 for (;;) 执行 tryAcquireShared 成功则让读锁计数加一 这时 t2 已经恢复运行，接下来 t2 调用 setHeadAndPropagate(node, 1)，它原本所在节点被置为头节点 123456789101112131415161718192021222324252627282930 private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125; &#125;private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 事情还没完，在 setHeadAndPropagate 方法内还会检查下一个节点是否是 shared，如果是则调用doReleaseShared() 将 head 的状态从 -1 改为 0 并唤醒老二，这时 t3 在 doAcquireShared 内parkAndCheckInterrupt() 处恢复运行 这回再来一次 for (;;) 执行 tryAcquireShared 成功则让读锁计数加一 这时 t3 已经恢复运行，接下来 t3 调用 setHeadAndPropagate(node, 1)，它原本所在节点被置为头节点 下一个节点不是 shared 了，因此不会继续唤醒 t4 所在节点 t2 r.unlock，t3 r.unlockt2 进入 sync.releaseShared(1) 中，调用 tryReleaseShared(1) 让计数减一，但由于计数还不为零 123456789101112131415161718192021222324252627282930313233343536373839404142public void unlock() &#123; sync.releaseShared(1);&#125;public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125;protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125;&#125; t3 进入 sync.releaseShared(1) 中，调用 tryReleaseShared(1) 让计数减一，这回计数为零了，进入 doReleaseShared() 将头节点从 -1 改为 0 并唤醒老二，即 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 之后 t4 在 acquireQueued 中 parkAndCheckInterrupt 处恢复运行，再次 for (;;) 这次自己是老二，并且没有其他 竞争，tryAcquire(1) 成功，修改头结点，流程结束 其实写锁就是独占锁 也就是独占模式 和reentrantLock走的同一套流程，(重写tryAcquire)读锁时共享锁 共享模式。(重写tryAcquireShare) StampedLock该类自 JDK 8 加入，是为了进一步优化读性能，它的特点是在使用读锁、写锁时都必须配合【戳】使用 123456789101112131415161718192021222324252627282930313233343536373839404142class DataContainerStamped &#123; private int data; private final StampedLock lock = new StampedLock(); public DataContainerStamped(int data) &#123; this.data = data; &#125; public int read(int readTime) &#123; //StampedLock应该是利用了偏向锁+乐观锁的概念,读读之间的加锁，不会频繁cas操作，只有当 //有写锁加上时，才会锁升级成读锁 long stamp = lock.tryOptimisticRead(); log.debug(&quot;optimistic read locking...&#123;&#125;&quot;, stamp); sleep(readTime); if (lock.validate(stamp)) &#123; log.debug(&quot;read finish...&#123;&#125;, data:&#123;&#125;&quot;, stamp, data); return data; &#125; // 锁升级 - 读锁 log.debug(&quot;updating to read lock... &#123;&#125;&quot;, stamp); try &#123; stamp = lock.readLock(); log.debug(&quot;read lock &#123;&#125;&quot;, stamp); sleep(readTime); log.debug(&quot;read finish...&#123;&#125;, data:&#123;&#125;&quot;, stamp, data); return data; &#125; finally &#123; log.debug(&quot;read unlock &#123;&#125;&quot;, stamp); lock.unlockRead(stamp); &#125; &#125; public void write(int newData) &#123; long stamp = lock.writeLock(); log.debug(&quot;write lock &#123;&#125;&quot;, stamp); try &#123; sleep(2); this.data = newData; &#125; finally &#123; log.debug(&quot;write unlock &#123;&#125;&quot;, stamp); lock.unlockWrite(stamp); &#125; &#125;&#125; Semaphore信号量，用来限制能同时访问共享资源的线程上线。 123456789101112131415161718192021222324public static void main(String[] args) &#123; // 1. 创建 semaphore 对象 Semaphore semaphore = new Semaphore(3); // 2. 10个线程同时运行 for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; // 3. 获取许可 try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; log.debug(&quot;running...&quot;); sleep(1); log.debug(&quot;end...&quot;); &#125; finally &#123; // 4. 释放许可 semaphore.release(); &#125; &#125;).start(); &#125; &#125; 原理Semaphore内部同样有一个aqs同步器。 123456789101112131415161718192021public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125; static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; //sync的构造 super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125; &#125;Sync(int permits) &#123; setState(permits);&#125; Semaphore 有点像一个停车场，permits 就好像停车位数量，当线程获得了 permits 就像是获得了停车位，然后 停车场显示空余车位减一 刚开始，permits（state）为 3，这时 5 个线程来获取资源。（semaphore.acquire()）· 123456789101112131415161718192021222324public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;//默认调用非公平锁的tryAcquireShared final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125;&#125; 假设其中 Thread-1，Thread-2，Thread-4 cas 竞争成功，而 Thread-0 和 Thread-3 竞争失败，进入 AQS 队列park 阻塞。 1234567891011121314151617181920212223242526272829/** * Acquires in shared interruptible mode. * @param arg the acquire argument */private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 这时 Thread-4 释放了 permits，状态如下 (release方法) 123456789101112131415161718192021222324252627282930313233343536373839404142 public void release() &#123; sync.releaseShared(1); &#125; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125;protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) return true; &#125;&#125; //唤醒队列中的节点 private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125; 接下来 Thread-0 竞争成功 (doAcquireSharedInterruptibly方法 for循环执行)，permits 再次设置为 0，设置自己为 head 节点，断开原来的 head 节点，unpark 接 下来的 Thread-3 节点，但由于 permits 是 0，因此 Thread-3 在尝试不成功后再次进入 park 状态 CountdownLatch 用来进行线程同步协作，等待所有线程完成倒计时。 其中构造参数用来初始化等待计数值，await() 用来等待计数归零，countDown() 用来让计数减一 12345678910111213141516171819202122232425public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(3); new Thread(() -&gt; &#123; log.debug(&quot;begin...&quot;); sleep(1); latch.countDown(); log.debug(&quot;end...&#123;&#125;&quot;, latch.getCount()); &#125;).start(); new Thread(() -&gt; &#123; log.debug(&quot;begin...&quot;); sleep(2); latch.countDown(); log.debug(&quot;end...&#123;&#125;&quot;, latch.getCount()); &#125;).start(); new Thread(() -&gt; &#123; log.debug(&quot;begin...&quot;); sleep(1.5); latch.countDown(); log.debug(&quot;end...&#123;&#125;&quot;, latch.getCount()); &#125;).start(); log.debug(&quot;waiting...&quot;); latch.await(); log.debug(&quot;wait end...&quot;);&#125; 原理CountdownLatch内部同样维护一个aqs同步器 12345678910111213141516171819202122232425262728//将aqs内部成员变量设置为指定值CountDownLatch countDownLatch = new CountDownLatch(3); //每次countDown都会-1public void countDown() &#123; sync.releaseShared(1); &#125; public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; //唤醒主线程await方法 doReleaseShared(); return true; &#125; return false; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125;//倒计时未结束也就是state还未=0时 执行这个方法 进入阻塞队列 private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; CyclicBarrier循环栅栏，用来进行线程协作，等待线程满足某个计数。构造时设置『计数个数』，每个线程执行到某个需要“同步”的时刻调用 await() 方法进行等待，当等待的线程数满足『计数个数』时，继续执行 12345678910111213141516171819202122232425CyclicBarrier cb = new CyclicBarrier(2，()-&gt;&#123; //当await的线程全部运行完后，就会执行后面的方法 System.out.println(&quot;线程1 线程2 finish....&quot;);&#125;); new Thread(()-&gt;&#123; System.out.println(&quot;线程1开始..&quot;+new Date()); try &#123; cb.await(); // 当个数不足时，等待 &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;线程1继续向下运行...&quot;+new Date());&#125;).start();new Thread(()-&gt;&#123; System.out.println(&quot;线程2开始..&quot;+new Date()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; try &#123; cb.await(); // 2 秒后，await线程个数够2，继续运行 &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;线程2继续向下运行...&quot;+new Date());&#125;).start();//CyclicBarrier可以重复使用 当await调用两次 计数 变成0后，又可以再次await 再恢复成2 CompletableFuture 基本用法1234567891011121314151617181920212223242526272829CompletableFuture.runAsync(Runnable runnable);CompletableFuture.runAsync(Runnable runnable, Executor executor);CompletableFuture.supplyAsync(Supplier supplier);CompletableFuture.supplyAsync(Supplier supplier, Executor executor)//通过上面几个方法可以创建一个CompletableFuture CompletableFuture&lt;Double&gt; cf = CompletableFuture.supplyAsync(()-&gt;&#123; System.out.println(Thread.currentThread()+&quot; start,time-&gt;&quot;+System.currentTimeMillis()); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; &#125; if(false)&#123; throw new RuntimeException(&quot;test&quot;); &#125;else&#123; System.out.println(Thread.currentThread()+&quot; exit,time-&gt;&quot;+System.currentTimeMillis()); return 1.2; &#125; &#125;).whenComplete((res, e) -&gt; &#123; System.out.println(&quot;future01回调方法执行 ==》&quot; + res + &quot;，线程id：&quot; + Thread.currentThread().getId()+&quot;--&quot;+e); &#125;); System.out.println(&quot;run result-&gt;&quot;+cf.get());//阻塞 System.out.println(&quot;main thread exit,time-&gt;&quot;+System.currentTimeMillis());//runAsync 方法接收的是 Runnable 的实例，意味着它没有返回值//supplyAsync 方法对应的是有返回值的情况 不是callable 是一个供给型接口https://www.cnblogs.com/dtdx/p/14238516.html 回调 whenComplete、whenCompleteAsync123456//当CompletableFuture的计算结果完成，或者抛出异常的时候，可以执行特定的Action。主要是下面的方法：public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)public CompletableFuture&lt;T&gt; whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)//whenComplete：是执行当前任务的线程执行继续执行 whenComplete 的任务。//whenCompleteAsync：是执行把 whenCompleteAsync 这个任务继续提交给线程池来进行执行。 继续执行 thenApply thenAccept thenRunthenApply 方法：当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前任务的返回值。 thenAccept方法：消费处理结果。接收任务的处理结果，并消费处理，无返回结果。 thenRun方法：只要上面的任务执行完成，就开始执行thenRun，只是处理完任务后，执行 thenRun的后续操作 带有Async默认是异步执行的。这里所谓的异步指的是不在当前线程内执行。 thenRunAsync 123456789101112131415161718192021222324CompletableFuture&lt;Void&gt; future01 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;future01执行，线程id：&quot; + Thread.currentThread().getId()); return System.currentTimeMillis(); &#125;).thenRun(() -&gt; &#123; System.out.println(&quot;thenRun执行，无法获取上一步执行结果，无返回值&quot;); &#125;); System.out.println(future01.get()); CompletableFuture&lt;Void&gt; future02 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;future01执行，线程id：&quot; + Thread.currentThread().getId()); return System.currentTimeMillis(); &#125;).thenAccept((res) -&gt; &#123; System.out.println(&quot;thenAccept，上一步执行结果: &quot; + res +&quot;，无返回值&quot;); &#125;); System.out.println(future02.get()); CompletableFuture&lt;Long&gt; future03 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;future03执行，线程id：&quot; + Thread.currentThread().getId()); return System.currentTimeMillis(); &#125;).thenApply((res) -&gt; &#123; long i = 10; System.out.println(&quot;thenApply，上一步执行结果: &quot; + res + &quot;，有返回值: &quot; + i); return i; &#125;); 组合 两个都处理完成 thenCombine thenAcceptBoth runAfterBoth1234567891011121314151617thenCombine：组合两个future，获取两个future任务的返回结果，并返回当前任务的返回值thenAcceptBoth：组合两个future，获取两个future任务的返回结果，然后处理任务，没有返回值。runAfterBoth：组合两个future，不需要获取future的结果，只需两个future处理完任务后，处理该任务 CompletableFuture&lt;Void&gt; future03 = future01.runAfterBoth(future02, () -&gt; &#123; System.out.println(&quot;任务3开始。。。&quot;); &#125;); CompletableFuture&lt;Void&gt; future04 = future01.thenAcceptBoth(future02, (f1, f2) -&gt; &#123; System.out.println(&quot;任务4开始。。。之前的结果 &quot;+f1+&quot;==&gt;&quot;+f2); &#125;); CompletableFuture&lt;Long&gt; future05 = future01.thenCombine(future02, (f1, f2) -&gt; &#123; System.out.println(&quot;任务5开始。。。之前的结果 &quot;+f1+&quot;==&gt;&quot;+f2); return 0L; &#125;); 组合 只需一个处理完成123456789101112131415161718applyToEither：组合两个future，只需一个future任务的返回结果，并返回当前任务的返回值acceptEither：组合两个future，只需一个future任务的返回结果，然后处理任务，没有返回值。runAfterEither：组合两个future，不需要获取future的结果，只需一个future处理完任务后，处理该任务 CompletableFuture&lt;Void&gt; future03 = future01.runAfterEither(future02, () -&gt; &#123; System.out.println(&quot;任务3开始。。。&quot;); &#125;); CompletableFuture&lt;Void&gt; future04 = future01.acceptEither(future02, (res) -&gt; &#123; System.out.println(&quot;任务4开始。。。之前的结果 &quot;+res); &#125;); CompletableFuture&lt;Long&gt; future05 = future01.applyToEither(future02, (res) -&gt; &#123; System.out.println(&quot;任务5开始。。。之前的结果 &quot;+res); return 0L; &#125;); 多任务 allOf anyOf123456789allOf：等待所有任务完成 才会执行future03anyOf：只要有一个任务完成，都会执行future03 CompletableFuture&lt;Void&gt; future03 = CompletableFuture.allOf(future01, future02); CompletableFuture&lt;Object&gt; future04 = CompletableFuture.anyOf(future01, future02); System.out.println(&quot;anyOf 任意一个异步任务执行完成&quot;+future04.get()); System.out.println(&quot;allOf 等待所有异步任务执行完成&quot;+future03.get()); thenCompose 嵌套future123456CompletableFuture&lt;CompletableFuture&lt;Double&gt;&gt; result = getUserDetail(userId).thenApply(user -&gt; getCreditRating(user)); // getCreditRating也是一个CompletableFuture 返回了一个嵌套的CompletableFuture CompletableFuture&lt;Double&gt; result = getUserDetail(userId)//正确写法.thenCompose(user -&gt; getCreditRating(user));因此，规则就是-如果你的回调函数返回一个CompletableFuture，但是你想从CompletableFuture链中获取一个直接合并后的结果，这时候你可以使用thenCompose()。 异常处理 exceptionally handle12345678910111213141516171819202122232425262728293031323334exceptionally()回调给你一个从原始Future中生成的错误恢复的机会。你可以在这里记录这个异常并返回一个默认值。CompletableFuture&lt;String&gt; maturityFuture = CompletableFuture.supplyAsync(() -&gt; &#123;if(age &lt; 0) &#123;throw new IllegalArgumentException(&quot;Age can not be negative&quot;);&#125;if(age &gt; 18) &#123;return &quot;Adult&quot;;&#125; else &#123;return &quot;Child&quot;;&#125;&#125;).exceptionally(ex -&gt; &#123;System.out.println(&quot;Oops! We have an exception - &quot; + ex.getMessage());return &quot;Unknown!&quot;;&#125;);handle()从异常恢复，无论一个异常是否发生它都会被调用。Integer age = -1;CompletableFuture&lt;String&gt; maturityFuture = CompletableFuture.supplyAsync(() -&gt; &#123; if(age &lt; 0) &#123; throw new IllegalArgumentException(&quot;Age can not be negative&quot;); &#125; if(age &gt; 18) &#123; return &quot;Adult&quot;; &#125; else &#123; return &quot;Child&quot;; &#125;&#125;).handle((res, ex) -&gt; &#123; if(ex != null) &#123; System.out.println(&quot;Oops! We have an exception - &quot; + ex.getMessage()); return &quot;Unknown!&quot;; &#125; return res;&#125;); 线程安全的集合类遗留的安全集合 方法都是由synchronized修饰的，效率不高，不推荐使用。 修饰的安全集合,就是将原本不安全的集合类，传进去。通过装饰者模式，给每个线程不安全的集合类的方法，外层套一个synchronized。 JUC安全集合 ConcurrentHashMap 原理123456789101112131415161718192021222324252627// 默认为 0// 当初始化时, 为 -1// 当扩容时, 为 -(1 + 扩容线程数)// 当初始化或扩容完成后，为 下一次的扩容的阈值大小private transient volatile int sizeCtl;// 整个 ConcurrentHashMap 就是一个 Node[]static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;&#125;// hash 表transient volatile Node&lt;K,V&gt;[] table;// 扩容时的 新 hash 表private transient volatile Node&lt;K,V&gt;[] nextTable;// 扩容时如果某个 bin 迁移完毕, 用 ForwardingNode 作为旧 table bin 的头结点static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125;// 用在 compute 以及 computeIfAbsent 时, 用来占位, 计算完成后替换为普通 Nodestatic final class ReservationNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125;// 作为 treebin 的头节点, 存储 root 和 firststatic final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125;// 作为 treebin 的节点, 存储 parent, left, rightstatic final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;&#125; 123456789// 获取 Node[] 中第 i 个 Nodestatic final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) // cas 修改 Node[] 中第 i 个 Node 的值, c 为旧值, v 为新值static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) // 直接修改 Node[] 中第 i 个 Node 的值, v 为新值static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) 123456789101112public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); // tableSizeFor 仍然是保证计算出最终size的大小是 2^n, 即 16,32,64 ... 用于后面的hash计算 int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125; 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // spread 方法能确保返回结果是正数 int h = spread(key.hashCode()); //table就是hash表 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; //根据key的hashcode和tab长度取模 找到对应的头节点 赋给e (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果头结点已经是要查找的 key (hashcode相同) if ((eh = e.hash) == h) &#123; //头结点的key等于当前的key if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果找到的头节点e的hash值小于0代表该bin正在扩容(头节点是forwardingNode) //或者是treebin() 调用对应的find方法来查找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //正常遍历链表 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394public V put(K key, V value) &#123; return putVal(key, value, false); &#125;//onlyIfAbsent 是否不覆盖旧值 false表示覆盖新值final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不允许null的可以,hashmap就允许 if (key == null || value == null) throw new NullPointerException(); //保证正整数 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; // f是链表头节点 // fh是链表头结点的 hash // i是链表在 table 中的下标 // n是table的长度 Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) //初始化table 使用了cas tab = initTable(); //找到key的hashcode对应下标处的头节点 如果不存在则创建一个 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //cas创建 如果其他线程占用了,cas失败了 就继续循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //帮忙扩容 (头结点的hash值表示正在扩容) else if ((fh = f.hash) == MOVED) //帮忙之后 进入下一次循环 tab = helpTransfer(tab, f); //进入这个else表示不在扩容，不在初始化，发生了hash冲突 else &#123; V oldVal = null; //此时加锁了 锁住了这个桶的头节点 synchronized (f) &#123; //确认链表的头节点没有被移动 if (tabAt(tab, i) == f) &#123; //链表 if (fh &gt;= 0) &#123; binCount = 1; //遍历链表 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //找到了相同的key值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; //覆盖掉旧值 if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //没有找到key 新增追加到链表尾 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //红黑树 (TreeBin 红黑树的头节点) else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; // putTreeVal 会看 key 是否已经在树中, 是, 则返回对应的 TreeNode //然后更新操作,否 做新增操作 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; //代表有hash冲突 if (binCount != 0) &#123; //如果链表长度&gt;=树化阙值(8) 就会将链表转为红黑树 //(先扩容 到64 如果还是大于8 就会转换) if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 增加 size 计数 addCount(1L, binCount); return null;&#125; 123456789101112131415161718192021222324private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); //尝试将sizeCtl设置为-1 表示初始化table else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; //创建table,其他线程会在while()循环中yield 直至table创建 try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab; &#125; 应用场景 控制线程的执行顺序12345678910111213141516171819202122232425262728293031323334353637383940static final Object lock = new Objectstatic boolean t2runned = false;public static void main(String[] args)&#123; Thread t1 = new Thread(() -&gt;&#123; synchronized (Lock) &#123; while (!t2runned) &#123; try &#123; lock.wait(); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; Log.debug(&quot;1&quot;); &#125; &#125;,name: &quot;t1&quot;); Thread t2 = new Thread(() -&gt; &#123; synchronized (Lock) &#123; Log.debug(&quot;2&quot;); t2runned = true; lock.notify(); &#125;,name: &quot;t2&quot;); t1.start();t2.start(); //park unparkThread t1 = new Thread(() -&gt;&#123; LockSupport.park(); Log.debug(&quot;1&quot;&quot;);&#125;,name: &quot;t1&quot;); t1.start(); new Thread(() -&gt;&#123; log.debug(&quot;2&quot;); LockSupport.unpark(t1);&#125;, name: &quot;t2&quot; ).start(); 交替输出1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class waitNotify &#123; //等待标记 private int flag; //循环次数 private int loopNumber; public waitNotify(int flag, int loopNumber) &#123; this.flag = flag; this.loopNumber = loopNumber; &#125; public void print(String str, int waitFlag， int nextFlag)&#123; for (int i = 0; i &lt; loopNumber; i++) &#123; synchronized (this) &#123; while(flag != waitFlag) &#123; try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printstackTrace(); &#125; System.out.print(str); flag = nextFlag; this.notifyAll(); &#125; &#125; &#125; &#125; public static void main(String[]args) &#123; waitNotify wn = new waitNotify(1,5); new Thread(() -&gt;&#123; wn.print(&quot;a&quot;,1,2); &#125;).start(); new Thread(() -&gt;&#123; wn.print(&quot;b&quot;,2,3); &#125;).start(); new Thread(() -&gt;&#123; wn.print(&quot;c&quot;,3,1); &#125;).start();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void main(String[] args) &#123; Awaitsignal awaitsignal = new Awaitsignal(loopNumber:5); condition a = awaitsignal.newCondition(); condition b = awaitsignal.newCondition(); condition c = awaitsignal.newCondition(); new Thread(()-&gt;&#123; awaitSignal.print(&quot;a&quot;,a,b); &#125;).start(); new Thread(()-&gt;&#123; awaitSignal.print(&quot;b&quot;,b,c); &#125;).start(); new Thread(()-&gt;&#123; awaitSignal.print(&quot;c&quot;,c,a); &#125;).start(); a.signal();&#125;class Awaitsignal extends ReentrantLock&#123; private int loopNumber; public Awaitsignal(int loopNumber) &#123; this.loopNumber = loopNumber; &#125; //参数1打印内容.参数2进入哪一件休息室 参数3 下一间休息室 public void print(String str，Condition current，Condition next)&#123; for (int i = 0; i &lt; loopNumber; i++) &#123; lock(); try &#123; current.await(); System.out.print(str); next.signal(): &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; unlock(); &#125; &#125; &#125; &#125; JMM简单的说，JMM定义了一套在多线程读写共享数据时（成员变量、数组)时，对数据的可见性、有序性、和原子性的规则和保障。 原子性通过synchronized保证原子性。 可见性可以通过volatile关键字来解决这个问题 volatile如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 volatile的两条实现原则:Lock前缀指令会引起处理器缓存回写到内存一个处理器的缓存回写到内存会导致其他处理器的缓存无效 volatile只能保证可见性，并不能保证原子性。synchronized两者都能保证，但是是重量级操作，性能相对较低。 volatile也能禁止指令重排 原理内存屏障: 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插人一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存 volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读&#x2F;写操作重排序 LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序 LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。 指令重排对与单例模式 懒汉法实现，双重check方法，在多线程环境下可能会因为指令重排出现问题。 1234567891011121314151617public final class Singleton &#123; private singleton( ) &#123; &#125; private static singleton INSTANCE = null; Wpublic staticjsingleton getInstance() &#123; //实例没创建，才会进入内部的synchronized代码块 if(INSTANCE == null) &#123; synchronized (Singleton.class) &#123; //也许有其它线程已经创建实例，所以再判断一次 if (INSTANCE == null) &#123; INSTANCE = new Singleton( ); &#125; &#125; &#125; return INSTANCE;&#125;&#125; INSTANCE &#x3D; new Singleton()对应的字节码为:其中47两步的顺序不是固定的，也许jvm 会优化为:先将引用地址赋值给INSTANCE变量后，再执行构造方法(因为对结果不会造成影响)，如果两个线程t1，t2按如下时间序列执行: 这时t1还未完全将构造方法执行完毕，如果在构造方法中要执行很多初始化操作，那么t2拿到的是将是一个未初始化完毕的单例。 对INSTANCE使用volatile修饰即可，可以禁用指令重排，但要注意在JDK 5以上的版本的volatile才会真正有效 happens-beforehappens-before规定了哪些写操作对其它线程的读操作可见，它是可见性与有序性的一套规则总结: 线程对volatile变量的写，对接下来其它线程对该变量的读可见 线程解锁m之前对变量的写，对于接下来对m加锁的其它线程对该变量的读可见也就是说线程1锁住M对象，然后对一个变量A做了修改，另一个需要锁M对象的锁在获取到锁之后,对于变量A的修改是可见的 线程start前对变量的写，对该线程开始后对该变量的读可见 线程结束前对变量的写，对其它线程得知它结束后的读可见(比如其它线程调用t1.isAlive()或t1.join()等待它结束) 线程t1打断t2( interrupt)前对变量A的写，对于其他线程得知t2被打断后对变量A的读可见（通过t2.interrupted或 t2.isInterrupted) 对变量默认值(0, false,null)的写，对其它线程对该变量的读可见 CASCAS即Compare and Swap，它体现的一种乐观锁的思想，比如多个线程要对一个共享的整型变量执行+1操作: 12345678910111213//需要不断尝试while(true) &#123; int旧值=共享变量;//比如拿到了当前值0 int结果=旧值+1;//在旧值О的基础上增加1，正确结果是1 /* 这时候如果别的线程把共享变量改成了5，本线程的正确结果1就作废了，这时候compareAndSwap返回 false，重新尝试，直到:compareAndSwap返回true，表示我本线程做修改的同时，别的线程没有干扰 */ //旧值会先和共享变量比较 相同时才会返回true，然后将结果更新到共享变量上。 if(compareAndSwap (旧值，结果))&#123; //成功，退出循环 &#125;&#125; 获取共享变量时，为了保证该变量的可见性，需要使用volatile修饰。结合CAS和volatile可以实现无锁并发，适用于竞争不激烈、多核CPU的场景下。|因为没有使用synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 juc (java.util.concurrent）中提供了原子操作类，可以提供线程安全的操作，例如: AtomicInteger、AtomicBoolean等，它们底层就是采用CAS技术+volatile来实现的。 LongAdder 原子累加器LongAdder累计相比于AtomicInteger效率提升很大。 性能提升的原因很简单，就是在有竞争时，设置多个累加单元，Therad-0累加Cel[0]，而Thread-l 累加Cell[1]..最后将结果汇总。这样它们在累加时操作的不同的Cell变量，因此减少了CAS重试失败，从而提高性能。 原理LongAdder类有几个关键域 123456//累加单元数组，懒惰初始化transient volatile cell[] cells;//基础值，如果没有竞争，则用cas累加这个域transient volatile long base;//在 cells 创建或扩容时，置为1，表示加锁 (cas锁)transient volatileiit cellsBusy; 12345678910111213141516// 不要用于实践！！！public class LockCas &#123; private AtomicInteger state = new AtomicInteger(0); public void lock() &#123; while (true) &#123; if (state.compareAndSet(0, 1)) &#123; break; &#125; &#125; &#125; public void unlock() &#123; log.debug(&quot;unlock...&quot;); state.set(0); &#125;&#125; 原理之伪共享 12345678910111213// 防止缓存行伪共享@sun.misc.Contendedstatic final class Cell &#123; volatile long value; Cell(long x) &#123; value = x; &#125; // 最重要的方法, 用来 cas 方式进行累加, prev 表示旧值, next 表示新值 final boolean cas(long prev, long next) &#123; return UNSAFE.compareAndSwapLong(this, valueOffset, prev, next); &#125; // 省略不重要代码&#125; 缓存和内存的速度对比因为 CPU 与 内存的速度差异很大，需要靠预读数据至缓存来提升效率。 而缓存以缓存行为单位，每个缓存行对应着一块内存，一般是 64 byte（8 个 long） 缓存的加入会造成数据副本的产生，即同一份数据会缓存在不同核心的缓存行中 CPU 要保证数据的一致性，如果某个 CPU 核心更改了数据，其它 CPU 核心对应的整个缓存行必须失效 因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 为 24 字节（16 字节的对象头和 8 字节的 value），因此缓存行可以存下 2 个的 Cell 对象。这样问题来了：Core-0 要修改 Cell[0]Core-1 要修改 Cell[1]无论谁修改成功，都会导致对方 Core 的缓存行失效，比如 Core-0 中 Cell[0]&#x3D;6000, Cell[1]&#x3D;8000 要累加Cell[0]&#x3D;6001, Cell[1]&#x3D;8000 ，这时会让 Core-1 的缓存行失效 这样就会影响效率。 @sun.misc.Contended 用来解决这个问题，它的原理是在使用此注解的对象或字段的前后各增加 128 字节大小的padding，从而让 CPU 将对象预读至缓存时占用不同的缓存行，这样，不会造成对方缓存行的失效 1234567891011121314151617181920212223242526public void add(long x) &#123; // as 为累加单元数组 // b 为基础值 // x 为累加值 Cell[] as; long b, v; int m; Cell a; // 进入 if 的两个条件 // 1. as 有值, 表示已经发生过竞争, 进入 第二个if // 2. cas 给 base 累加时失败了, 表示 base 发生了竞争, 进入 if if ((as = cells) != null || !casBase(b = base, b + x)) &#123; // uncontended 表示 cell 没有竞争 boolean uncontended = true; if ( // as 还没有创建 as == null || (m = as.length - 1) &lt; 0 || // 当前线程对应的 cell 还没有创建 (a = as[getProbe() &amp; m]) == null || // cas 给当前线程的 cell 累加失败 uncontended=false ( a 为当前线程的 cell ) !(uncontended = a.cas(v = a.value, v + x)) ) &#123; // 进入 cell 数组创建、cell 创建的流程 longAccumulate(x, null, uncontended); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) &#123; int h; // 当前线程还没有对应的 cell, 需要随机生成一个 h 值用来将当前线程绑定到 cell if ((h = getProbe()) == 0) &#123; // 初始化 probe ThreadLocalRandom.current(); // h 对应新的 probe 值, 用来对应 cell h = getProbe(); wasUncontended = true; &#125; // collide 为 true 表示需要扩容 boolean collide = false; for (;;) &#123; Cell[] as; Cell a; int n; long v; // 已经有了 cells if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; if ((a = as[(n - 1) &amp; h]) == null) &#123; // 为 cellsBusy 加锁, 创建 cell, cell 的初始累加值为 x // 成功则 break, 否则继续 continue 循环 &#125; // 有竞争, 改变线程对应的 cell 来重试 cas else if (!wasUncontended) wasUncontended = true; // cas 尝试累加, fn 配合 LongAccumulator 不为 null, 配合 LongAdder 为 null else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; //如果 cells 长度已经超过了最大长度(CPU核心数), 或者已经扩容, //改变线程对应的 cell 来重试 cas else if (n &gt;= NCPU || cells != as) collide = false; // 确保 collide 为 false 进入此分支, 就不会进入下面的 else if 进行扩容了 else if (!collide) collide = true; // 加锁 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; // 加锁成功, 扩容 continue; &#125; // 改变线程对应的 cell h = advanceProbe(h); &#125; // 还没有 cells, 尝试给 cellsBusy 加锁 else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; // 加锁成功, 初始化 cells, 最开始长度为 2, 并填充一个 cell // 成功则 break; &#125; // 上两种情况失败, 尝试给 base 累加 如果再失败 就无法执行break 再次循环 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; &#125;&#125; 123456789101112public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; synchronized优化Java HotSpot虚拟机中，每个对象都有对象头（包括class指针和Mark Word) 。Mark Word平时存储这个对象的哈希码、分代年龄，当加锁时，这些信息就根据情况被替换为标记位、线程锁记录指针、重量级锁指针、线程ID等内容。 轻量级锁每个线程都的栈帧都会包含一个锁记录的结构，内部可以存储锁定对象的Mark Word让锁记录中Object reference指向锁对象，并尝试用cas替换Object的Mark Word，也会将Mark Word的值存入锁记录（lock record）。 lock record 后面的 00 表示轻量级锁 01表示正常状态 前面30位表示锁记录地址 如果cas 失败，有两种情况 如果是其它线程已经持有了该Object的轻量级锁，这时表明有竞争，进入锁膨胀过程 如果是自己执行了synchronized锁重入，那么再添加一条Lock Recorrd 作为重入的计数 当退出synchronized代码块（解锁时）如果有取值为null的锁记录，表示有重入，这时重置锁记录，表示重入计数减一。 当退出synchronized代码块（解锁时）锁记录的值不为null，这时使用cas将Mark Word 的值恢复给对象头 成功，则解锁成功 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程 12345678910111213static Object obj = new Object();public static void method1() &#123; synchronized( obj ) &#123; // 同步块 A method2(); &#125;&#125;public static void method2() &#123; synchronized( obj ) &#123; // 同步块 B &#125;&#125; 锁膨胀如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁。 为Object对象申请 Monitor锁，让object指向重量级锁地址 然后自己进入Monitor的EntryList BLOCKED 当Thread-0退出同步块解锁时，使用cas将Mark Word 的值恢复给对象头，会失败。这时会进入重量级解锁流程，即按照Monitor地址找到Monitor对象，设置Owner为null，唤醒EntryList中 BLOCKED线程。 重量级锁的优化 自旋优化重量级锁竞争的时候，还可以使用自旋来进行优化，如果当前线程自旋成功（即这时候持锁线程已经退出了同步块，释放了锁），这时当前线程就可以**避免阻塞 减少上下文切换 **。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能。 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。 自旋成功自旋失败 偏向锁轻量级锁在没有竞争时（就自己这个线程），每次重入仍然需要执行 CAS 操作。Java 6 中引入了偏向锁来做进一步优化：只有第一次使用 CAS 将线程 ID 设置到对象的 Mark Word 头(不是设置锁记录地址了)，之后发现这个线程 ID是自己的就表示没有竞争，不用重新 CAS。 撤销偏向需要将持锁线程升级为轻量级锁，这个过程中所有线程需要暂停（STW） 访问对象的 hashCode 也会撤销偏向锁 因为hashCode本来是存到mark里的，然后由于加锁到了线程中，此时其他对象想获取这个对象的hashcode就拿不到了。 如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2， 重偏向会重置对象的 Thread ID 撤销偏向和重偏向都是批量进行的，以类为单位 如果撤销偏向到达某个阈值，整个类的所有对象都会变为不可偏向的 可以主动使用 -XX:-UseBiasedLocking 禁用偏向锁 一个对象创建时： 如果开启了偏向锁（默认开启），那么对象创建后，markword值为0x05即最后3位为101,这时它的 thread、epoch、age都为0。 偏向锁是默认是延迟的，不会在程序启动时立即生效，如果想避免延迟，可以加VM参数- XX:BiasedLockingStartupDelay&#x3D;g来禁用延迟。 如果没有开启偏向锁，那么对象创建后，markword值为Ox01即最后3位为00l,这时它的hashcode、age 都为0，第一次用到hashcode时才会赋值。synchronized 其它优化 减少上锁时间 减少锁的粒度 锁粗化 多次循环进入同步块不如同步块内多次循环 锁消除 JVM 会进行代码的逃逸分析，例如某个加锁对象是方法内局部变量，不会被其它线程所访问到，这时候就会被即时编译器忽略掉所有同步操作","categories":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java基础，JUC","slug":"Java基础，JUC","permalink":"http://example.com/tags/Java%E5%9F%BA%E7%A1%80%EF%BC%8CJUC/"}]},{"title":"Mysql","slug":"Mysql","date":"2023-06-26T02:24:54.879Z","updated":"2023-07-07T13:33:46.938Z","comments":true,"path":"2023/06/26/Mysql/","link":"","permalink":"http://example.com/2023/06/26/Mysql/","excerpt":"","text":"# 一条sql语句是如何执行的 MySQL 可以分为 Server 层和存储引擎层两部分 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。 也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine&#x3D;memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。 从图中不难看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分。 连接器第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的 1mysql -h$ip -P$port -u$user -p 输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。 连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。 如果用户名或密码不对，你就会收到一个”Access denied for user“的错误，然后客户端程序结束执行。 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。 数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。 怎么解决这个问题呢？你可以考虑以下两种方案。 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。 MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。 但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样： 1mysql&gt; select SQL_CACHE * from T where ID=10； 需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。 分析器如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。 MySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。 做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。 优化器经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。 比如你执行下面这样的语句，这个语句是执行两个表的 join： 1mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20; 既可以先从表 t1 里面取出 c&#x3D;10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。 也可以先从表 t2 里面取出 d&#x3D;20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。 这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。 优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容 执行器MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的： 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 至此，这个语句就执行完成了。 对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。 你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。 mysql分为service层和存储层，存储引擎层是插件式的，innodb是默认的存储引擎。service层分为连接器、分析器、优化器、执行器客户端和mysql服务器建立tcp连接，然后验证用户密码、权限之后，连接成功，会查询缓存(8之后移除)，没有命中就开始执行语句，先经过分析器 词法分析 知道要做什么、语法分析、检测是否符合mysql规则，然后优化器，对使用那个索引，多表关联决定各个表的执行顺序 日志系统只要我们写的是DML语句（insert,update,delete,create）等等，那么我们在数据库服务端执行的时候就会涉及到 redo log(重做日志) 和 binlog(归档日志) 两个日志文件的变动。 redo logWAL技术MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。在 MySQL 里有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。 当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到日志里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 redo log是一个特定的区域，写入操作是顺序写，非常快，而将数据刷新到磁盘是随机io，比较慢，所以要先写入redo log。 WAL操作这样可以避免每次更新都要通过磁盘随机 IO 定位到记录位置。 将改动以顺序 IO 写到 redo log。可以使用组提交来批量更新. InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。redo log 是 InnoDB引擎所特有的，所以我们如果再使用InnoDB引擎创建表时，如果数据库发生异常重启，之前提交的记录都不会丢失。 InnoDB正因为有了 redo log(重做日志)，才有了 crash-safe 的能力（即使mysql服务宕机，也不会丢失数据的能力）。 ** redo log 只会记录未刷盘的日志，已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除 （猜测后台有线程）** redo log 的写入机制这三种状态分别是： 存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分； 写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分； 持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。 日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值： 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。 InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。与binlog不同，binlog是每个线程都有一个binlog cache，而redo log是多个线程共用一个redo log buffer。事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。 除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。innodb_log_buffer_size 决定 innodb 重做日志缓存池的大小,默认是 8MB 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。 如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次， 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 binlogMySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜,redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。binlog是追加写，crash时不能判定binlog中哪些内容是已经写入到磁盘，哪些还没被写入,所以不能单依靠binlog支持崩溃恢复。而redolog是循环写，从check point到write pos (不是write pos到check point)间的内容都是未写入到磁盘的，但是redolog是无法支持归档的。redo log 和 binlog 有一个很大的区别就是，一个是循环写，一个是追加写。也就是说 redo log 只会记录未刷盘的日志，已经刷入磁盘的数据都会从 redo log 这个有限大小的日志文件里删除。binlog 是追加日志，保存的是全量的日志。 当数据库 crash 后，想要恢复未刷盘但已经写入 redo log 和 binlog 的数据到内存时，binlog 是无法恢复的。虽然 binlog 拥有全量的日志，但没有一个标志让 innoDB 判断哪些数据已经刷盘，哪些数据还没有。 这两种日志有以下三点不同。 redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 两阶段提交有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。 仍然用前面的 update 语句来做例子。假设当前 ID&#x3D;2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？ 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。 可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？ 其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。 Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。 两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。1、如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。2、时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？ 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整： a. 如果是，则提交事务； b. 否则，回滚事务。 binlog的三种格式statement当 binlog_format&#x3D;statement 时，binlog 里面记录的就是 SQL 语句的原文 123mysql&gt; delete from t /*comment*/ where a&gt;=4 and t_modified&lt;=&#x27;2018-11-10&#x27; limit 1;show binlog events in &#x27;master.000001&#x27;; 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务； 第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。 row可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。 Table_map event，用于说明接下来要操作的表是 test 库的表 t;Delete_rows event，用于定义删除的行为。可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id&#x3D;4 的行，不会有主备删除不同行的问题。 mixed因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。 binlog 的写入机制binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。 一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。 每个线程有自己 binlog cache，但是共用同一份 binlog 文件。 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog&#x3D;0 的时候，表示每次提交事务都只 write，不 fsync；sync_binlog&#x3D;1 的时候，表示每次提交事务都会执行 fsync；sync_binlog&#x3D;N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。 redo log 和 binlog 是怎么关联起来的?它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。如果完整，则提交事务，如果binlog不完整，则回滚事务 组提交LSN日志逻辑序列号（log sequence number，LSN）LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。 LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo logtrx1 是第一个到达的，会被选为这组的 leader；等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；trx1 去写盘的时候，带的就是 LSN&#x3D;160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；这时候 trx2 和 trx3 就可以直接返回了。 在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。 如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。 WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀? redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快； 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。 刷盘当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。有四种情况会刷盘： 当innoDB的redo log写满了，这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。checkPoint推进的过程中 会把推进路上对应的内存中的所有脏页都flush到磁盘上。redolog环对应的可以继续写入的部分要么是新的，要么是内存中的干净页，可以直接覆盖的。redolog对应的有用的部分对应的是内存中的脏页 当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。 当mysql认为系统空闲的时候就会刷盘 当mysql关闭前也会刷盘 当出现第一种情况的时候，整个系统就不能在更新了，因为写redolog是更新的必须程序，所有的更新都会被堵住，所以是要尽量避免的 InnoDB 用缓冲池（buffer pool）管理内存 脏页的控制策略通过i**nnodb_io_capacity **这个参数，它会告诉 InnoDB 你的磁盘能力,建议设置成磁盘的IOPS“IOPS全称:Input/Output Operations Per Second,即每秒进行读写(I/O)操作的次数。” InnoDB 的刷盘速度是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。 参数** innodb_max_dirty_pages_pct** 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字 F1(M)， 对于redolog,InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字 F2（N） 然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。 事务简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。 事务的 ACID（Atomicity、Consistency、Isolation、Durability，即原子性:每个事务都是不可分割的最小单元，要么全部成功，要不全部失败恢复到执行事务前的状态一致性:事务总是使得数据库从一个一致性状态到另一种一致性状态。隔离性:在并发的执行事务时，事务之间是不会造成影响的持久性:一旦事务提交。那么这个事务一定是生效的，即使遭遇到了崩溃宕机。通过redoLog+binlog实现） 隔离性与隔离级别当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释： 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么 隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。(mysql默认隔离级别 可重复读) 配置的方式是，将启动参数** transaction-isolation** 的值设置成** READ-COMMITTED**。你可以用 show variables 来查看当前的值 可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。假设你在管理一个个人银行账户表。一个表存了账户余额，一个表存了账单明细。到了月底你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响 事务隔离的实现我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。 在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。 你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。 基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在RR的隔离级别里，长事务的执行期间，其他事务每次开启，都会保留这次事务初始状态的read-view,这样就能保证在长事务的执行过程中看到的其他数据都是最初始的，但是这样就会导致老的事务视图、以及回滚日志必须存在，占用了大量的存储空间 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。 事务的启动方式如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。 MySQL 的事务启动方式有以下几种：显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。set autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。 这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。 有些客户端连接框架会默认连接成功后先执行一个 set autocommit&#x3D;0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。因此，我会建议你总是使用 set autocommit&#x3D;1, 通过显式语句的方式来启动事务。 但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。 如果你也有这个顾虑，我建议你使用 commit work and chain 语法。在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。 同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。 你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。 1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 可重复读的理解在 MySQL 里，有两个“视图”的概念：一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。 它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据” InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。 图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。 实际上，图中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。 按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见 因此，一个事务只需要在启动的时候声明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。事务执行之后，其他事务的更新对它虽然不可见，但是数据版本还是可见的，因为数据库实际上存储的是最新版本的数据。但是对于该事务来说，需要根据版本号以及Undo Logs计算出他需要的版本对应的数据 当然，如果“上一个版本”也不可见，那就得继续往前找。还有，如果是这个事务自己更新的数据，它自己还是要认的。 在实现上，** InnoDB 为每个事务构造了一个数组**，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。事务启动瞬间就会创建一个视图，并且生成一个trx_id 数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。 这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 落在黄色区域意味着是事务ID在低水位和高水位这个范围里面，而真正是是否可见，看黄色区域是否有这个值。如果黄色区域没有这个事务ID，则可见，如果有，则不可见。在这个范围里面并不意味这这个范围里有这个值，比如[1,2,3,5]，4在这个数组1-5的范围里，却没在这个数组里面。表示4是已提交的事务启动时看到的一批活跃事务id 不一定都是连续的，比如99，100，102，104，105。而事务id又是严格递增的，这是因为 101，103 事务虽然晚于99事务启动，但先提交了。所以也应该可见。**一个事务A，事务B，事务A先事务B启动 但是事务A执行第一个语句之前，事务B已经提交了，那么事务B对于事务A来说是可见的，其数据版本落在黄色部分。** InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 例题： 123456mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2); begin&#x2F;start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用** start transaction with consistent snapshot** 这个命令。第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。 这里，我们不妨做如下假设：事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。这样，事务 A 的视图数组就是[99,100], 事务 B 的视图数组是[99,100,101], 事务 C 的视图数组是[99,100,101,102]。如果使用第一种启动方式，事务A在最后查询才会创建视图，此时102版本低于高水位大于低水位，但是不在活跃数组中，所以102版本对于事务A可见，事务A查出的结果就是2。属于黄色区域第二种情况(事务c在事务A启动到创建视图这段时间间隔内提交了事务) 从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。 第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。每行数据的版本链中版本号不一定是递增的 好，现在事务 A 要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务 A 查询语句的读数据流程是这样的： 找到 (1,3) 的时候，判断出 row trx_id&#x3D;101，比高水位大(创建事务时确定高水位)，处于红色区域，不可见； 接着，找到上一个历史版本，一看 row trx_id&#x3D;102，比高水位大，处于红色区域，不可见； 再往前找，终于找到了（1,1)，它的 row trx_id&#x3D;90，比低水位小，处于绿色区域，可见。 这样执行下来，虽然期间这一行数据被修改过，但是事务 A 不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读 但是事务 B 的 update 语句，如果按照一致性读，好像结果不对哦？上图中，事务 B 的视图数组是先生成的，之后事务 C 才提交，不是应该看不见 (1,2) 吗，怎么能算出 (1,3) 来？是的，如果事务 B 在更新之前查询一次数据，这个查询返回的 k 的值确实是 1。 所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。事务与事务之间的隔离不应该影响最终数据的落地。就是说事务C先更新了数据，而后事务B也更新了同一份数据，以数据库的眼光来看这份数据的变动就是事务C的更新跟着事务B的更新，必须延续在一块而不能分开。 所以事务的更新必须是基于当前最新值来执行的，而读则是基于其视图，即可重复读的隔离，真的只是读层面的隔离。 在这个例子中，就是因为事务C的更新在前，事务B的更新必须延续事务C的结果，所以只能读取当前值再更新。而事务本身的更新是能被看到的，所以事务B再查询就只能是得到当前最新值。 因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。 所以，在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。 这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读 所以，如果把事务 A 的查询语句 select * from t where id&#x3D;1 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）共享锁就是可以事务可以继续加共享锁，但是不能加排他锁了。排他锁加上后就不能再加任何类型的锁不加锁叫快照读 12mysql&gt; select k from t where id=1 lock in share mode;mysql&gt; select k from t where id=1 for update; 再往前一步，假设事务 C 不是马上提交的，而是变成了下面的事务 C ，会怎么样呢？事务 C’的不同是，更新后并没有马上提交，在它提交前，事务 B 的更新语句先发起了。前面说过了，虽然事务 C’还没提交，但是 (1,2) 这个版本也已经生成了，并且是当前的最新版本。那么，事务 B 的更新语句会怎么处理呢？ 这时候，“两阶段锁协议”就要上场了。事务 C’没提交，也就是说 (1,2) 这个版本上的写锁还没释放。而事务 B 是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 C’释放这个锁，才能继续它的当前读。 可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 那么，我们再看一下，在读提交隔离级别下，事务 A 和事务 B 的查询语句查到的 k，分别应该是多少呢？这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 start transaction。 下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的 read view 框。（注意：这里，我们用的还是事务 C 的逻辑直接提交，而不是事务 C’） 这时，事务 A 的查询语句的视图数组是在执行这个语句的时候创建的，时序上 (1,2)、(1,3) 的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻：(1,3) 还没提交，不可见；(1,2) 提交了，属于情况 可见。所以，这时候事务 A 查询语句返回的是 k&#x3D;2。显然地，事务 B 查询结果 k&#x3D;3。 可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。 当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。 深入浅出索引索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。一本 500 页的书，如果你想快速找到其中的某一个知识点，在不借助目录的情况下，那我估计你可得找一会儿。同样，对于数据库的表而言，索引其实就是它的“目录” 其实最好的例子就是我们从小就用的字典 里面的声母查询方式就是聚簇索引。 偏旁部首就是二级索引 偏旁部首+笔画就是联合索引。 这种方式比较适合人类的思维方式，设计也比较精妙。 哈希哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。 不可避免地，多个 key 值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。 假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示： 图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。 需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。 你可以设想下，如果你现在要找身份证号在[ID_card_X, ID_card_Y]这个区间的所有用户，就必须全部扫描一遍了。 所以，哈希表这种结构适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。 有序数组有序数组在等值查询和范围查询场景中的性能就都非常优秀。 还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查 ID_card_n2 对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。 同时很显然，这个索引结构支持范围查询。你要查身份证号在[ID_card_X, ID_card_Y]区间的 User，可以先用二分法找到 ID_card_X（如果不存在 ID_card_X，就找到大于 ID_card_X 的第一个 User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。 如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。 二叉搜索树还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。 当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。 树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。 你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。 以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。 在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。而 InnoDB 存储引擎在 MySQL 数据库中使用最为广泛。 InnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。 每一个索引在 InnoDB 里面对应一棵 B+ 树。假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引 表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index） 主键索引和普通索引的查询有什么区别？ 如果语句是 select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树； 如果语句是 select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 索引维护B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。 而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。 除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50% 当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？ 由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 覆盖索引如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 最左前缀原则看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？ B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。 为了直观地说明这个概念，我们用（name，age）这个联合索引来分析可以看到，索引项是按照索引定义里面出现的字段顺序排序的。 联合索引先根据第一个字段排序，如果第一个字段有相同的，就按照第二个字段排序，注意，这里仅仅有相同的第一个字段情况下，才会根据第二个字段排序。 当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。 如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。 可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 在建立联合索引的时候，如何安排索引内的字段顺序。 这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。 这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。 索引下推上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： 1mysql&gt; select * from tuser where name like &#x27;张%&#x27; and age=10 and ismale=1; 你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。 因为联合索引在建立的时候是按照“字典序”来排序的，假设以(a,b)为例，先按照a的大小排序，如果a相等时再按照b的大小来排序：（2，100）、（3，150）、（4，50），第二个字段不一定有序，所以查询范围的时候最多匹配一个范围列，因为下一个字段不一定有序。 然后呢？当然是判断其他条件是否满足。在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数过程图如下:这两个图里面，每一个虚线箭头表示回表一次。第一个图中 在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。 第二个图中 InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。 explain在select语句之前添加explain关键字会返回语句的执行计划。 123456mysql&gt; explain select * from servers;+----+-------------+---------+------+---------------+------+---------+------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+---------+------+---------------+------+---------+------+------+-------+| 1 | SIMPLE | servers | ALL | NULL | NULL | NULL | NULL | 1 | NULL |+----+-------------+---------+------+---------------+------+---------+------+------+-------+ 其中最重要的type:NULLMySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。const、system当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用systemeq_ref类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件ref表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值range只检索给定范围的行，使用一个索引来选择行indexFull Index Scan，index与ALL区别为index类型只遍历索引树ALLFull Table Scan， MySQL将遍历全表以找到匹配的行 锁全局锁顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是** Flush tables with read lock** (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。 以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。 但是让整库都只读，听上去就很危险：如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。 你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。 所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。 表级锁MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁表锁的语法是 lock tables … read&#x2F;write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。 MDL另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 加读锁则所有线程可正常读元数据，不影响增删改查操作，只是不能修改表结构；加写锁则只有拥有锁的线程可以读写元数据，也就是修改表结构，其它线程不能执行任何操作，包括修改表结构与增删改查。(DDL 更改表结构) DML(增删改查) 我们来看一下下面的操作序列，假设表 t 是一个小表。我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。 之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。 如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了。 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。表不可用的原因是因为 sessionc 申请写锁 并且在队列处于优先，导致 sessionc 后面的所有 读锁 请求申请都被 block 了。这个时候客户端如果有频繁重试的逻辑就会导致不停的和数据库建立连接，把连接池打满导致库不可用。 你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。有未提交的事务时无法修改表字段，而且在存在长事务时执行修改表字段命令是一个危险的操作，可能阻塞其它增删改查请求，或导致线程爆满 如何安全地给小表加字段？首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？ 这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。 MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT&#x2F;WAIT n这个语法。 12ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 行锁MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。 顾名思义，行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。 在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放； 也就是说 如果一个事务中包含了对多条记录的增删改，每执行一条语句，就会对其中的一条记录加上对应的行锁，当事务提交时，才会释放锁，并不是语句执行完成释放。所有当一个事务包含了多条操作，影响了多行记录，尽量把并发度最高的操作放在最后，这样这行记录的行锁就不会在这个事务中停留很长的时间。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。 这时候，事务 A 在等待事务 B 释放 id&#x3D;2 的行锁，而事务 B 在等待事务 A 释放 id&#x3D;1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数** innodb_lock_wait_timeout** 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 **innodb_deadlock_detect **设置为 on，表示开启这个逻辑。 在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。 所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。 你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。 那如果是我们上面说到的所有事务都要更新同一行的场景呢？每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n平方) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。 怎么解决由热点更新导致的性能问题呢? 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。 另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。 因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。 也可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1&#x2F;10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。 加锁规则加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。原则 1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间。原则 2：查找过程中访问到的对象才会加锁。优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 12345678910CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 案例一这里 session A 要给索引 c 上 c&#x3D;5 的这一行加上读锁。 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。 要注意 c 是普通索引，因此仅访问 c&#x3D;5 这一条记录是不能马上停下来的，需要向右遍历，查到 c&#x3D;10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c&#x3D;5 这个等值条件，因此退化成间隙锁 (5,10)。 根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。 但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住（c的值）。 需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。 这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c&#x3D;5 lock in share mode 案例二根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；同时根据优化 2，这是一个等值查询 (id&#x3D;7)，而 id&#x3D;10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。所以，session B 要往这个间隙里面插入 id&#x3D;8 的记录会被锁住，但是 session C 修改 id&#x3D;10 这行是可以的。 案例三12mysql&gt; select * from t where id=10 for update;mysql&gt; select * from t where id&gt;=10 and id&lt;11 for update; 这两条语句，加锁范围相同吗？在逻辑上，这两条查语句肯定是等价的，但是它们的加锁规则不太一样。现在，我们就让 session A 执行第二个查询语句，来看看加锁效果。 开始执行的时候，要找到第一个 id&#x3D;10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁， 只加了 id&#x3D;10 这一行的行锁。 范围查找就往后继续找，找到 id&#x3D;15 这一行停下来，因此需要加 next-key lock(10,15]。此时是符 所以，session A 这时候锁的范围就是主键索引上，行锁 id&#x3D;10 和 next-key lock(10,15]。这样，session B 和 session C 的结果你就能理解了。 幻读在同一个事务中，两次读取到的数据不一致的情况称为幻读和不可重复读。幻读是针对insert导致的数据不一致，不可重复读是针对 delete、update导致的数据不一致 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。当前读指的是select for update或者select in share mode，指的是在更新之前必须先查寻当前的值，因此叫当前读 幻读只针对新增的记录，查询时记录条数不一样事务a 开启, 查询符合条件的数据 ,发现有10条, 准备将这10条记录修改, 此时事务b开启, 插入了一条符合事务a查询条件的记录. 提交事务, 回到事务a, a也提交事务, 当再次查询到时候, 发现修改了11条..感觉发生了幻觉一样. 此为幻读. 间隙锁12345678910CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 即使给所有行加上了锁，也避免不了幻读，这是因为给行加锁的时候，这条记录还不存在，没法加锁，因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。顾名思义，间隙锁，锁的就是两个值之间的空隙，比如下面5个数据(id值 0，5，10，15，20，25)，这就产生了 7 个间隙。这样，当执行 select * from t where id&#x3D;5 for update时，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。（如果只是给所有数据加上锁，那么对于新加入的数据 比如id=1 这一行是锁不住的，就会导致数据不一致的问题出现）所以数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。也就是说，跟行锁有冲突关系的是“另外一个行锁”。 但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。c7不存在 都会在这个间隙 加上锁，但是不会冲突 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。 这个 supremum 从哪儿来的呢？这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间 JoinNLJ123456789CREATE TABLE `t2` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`)) ENGINE=InnoDB;create table t1 like t2; 上面这个语句的执行流程 从表 t1 中读入一行数据 R； 从数据行 R 中，取出 a 字段到表 t2 里去查找； 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分； 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。 在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。如果使用 join 语句的话，需要让小表做驱动表。 BNL1select * from t1 straight_join t2 on (t1.a=t2.b); 这时候，被驱动表上没有可用的索引，算法的流程是这样的：“Block Nested-Loop Join”的算法，简称 BNL。 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存； 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。 可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000&#x3D;10 万次。在这种情况下，应该选择哪个表做驱动表? 假设小表的行数是 N，大表的行数是 M，那么在这个算法里：两个表都做一次全表扫描，所以总的扫描行数是 M+N；内存中的判断次数是 M*N。显然调换N和M没有区别 但是当join_buffer不足以放下表t1的数据时，mysql的策略就是分段放 能放下多少就先放多少，然后返回结果集之后，清空join_buffer继续放图中的步骤 4 和 5，表示清空 join_buffer 再复用。 假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ*N，显然λ的取值范围是 (0,1) 扫描行数是 N+λNM；内存判断 N*M 次。 所以结论是，应该让小表当驱动表。而λ的大小也会影响扫描的行数，而λ显然是受join_buffer_size影响，join_buffer_size 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。这就是为什么，你可能会看到一些建议告诉你，如果你的 join 语句很慢，就把 join_buffer_size 改大。 更准确地说，在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。 BKABatched Key Access(BKA)算法其实是对NLJ算法的优化 Multi-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。 NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。那怎么才能一次性地多传些值给表 t2 呢？方法就是，从表 t1 里一次性地多拿些行出来，一起传给表 t2。 既然如此，我们就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是 join_buffer。 图中，我在 join_buffer 中放入的数据是 P1P100，表示的是只会取查询需要的字段。当然，如果 join buffer 放不下 P1P100 的所有数据，就会把这 100 行数据分成多段执行上图的流程。 12set optimizer_switch=&#x27;mrr=on,mrr_cost_based=off,batched_key_access=on&#x27;; 前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于 MRR。 InnoDB 和 Memory 引擎的区别InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。 不同: InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的； 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值； 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引； InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。 InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。 内存表使用的是哈希索引是无法进行范围查询的，会走全表扫描。其实，一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快 但是为什么不建议你在生产环境上使用内存表。这里的原因主要包括两个方面：锁粒度问题；数据持久化问题。 内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。 数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。 实战普通索引和唯一索引，应该怎么选择？对于普通索引来说，查找到满足条件的第一个记录 后，需要查找下一个记录，直到碰到第一个不满足 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 这个不同带来的性能差距会有多少呢？答案是，微乎其微。 InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。 因为引擎是按页读写的，所以说，当找到 k&#x3D;5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。 当然，如果满足条件的这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。 change buffer当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。change buffer可以看成也是一个数据页，需要被持久化到 系统表空间（ibdata1），以及把这个change buffer页的改动记录在redo log里，事后刷进系统表空间（ibdata1）。 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k&#x3D;4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。 change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。Buffer Pool 是一片内存空间，受制于内存空间大小。 可以通过innodb_buffer_pool_size 来控制Buffer Pool 的大小。 现在来看一下插入一条记录的流程第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，找到要插入的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到 要插入的位置，插入这个值，语句执行结束。 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？ 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。 回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，建议尽量选择普通索引。 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。 change buffer 和 redo log举例： 1insert into t(id,k) values(id1,k1),(id2,k2); k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中这条更新语句做了如下的操作（按照图中的数字顺序）： Page 1 在内存中，直接更新内存； Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息 将上述两个动作记入 redo log 中（图中 3 和 4）。 做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。 同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。那在这之后的读请求，要怎么处理呢？ 比如，我们现在要执行 select * from t where k in (k1, k2)。以下这两个读请求的流程图。如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下上图的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。（merge后结果刷到磁盘上。） 可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。 MySQL为什么有时候会选错索引？写 SQL 语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由 MySQL 来确定的。 mysql对索引的是用是由mysql的server层的优化器决定的； 而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。 MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。 这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。 我们可以使用 show index 方法，看到一个索引的基数 那么，MySQL 是怎样得到索引的基数的呢？这里，我给你简单介绍一下 MySQL 采样统计的方法。 采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。 而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1&#x2F;M 的时候，会自动触发重新做一次索引统计。 在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。 为什么我的MySQL会“抖”一下？一条 SQL 语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。 InnoDB 在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作 redo log（重做日志），在更新内存写完 redo log 后，就返回给客户端，本次更新成功。 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 不论是脏页还是干净页，都在内存中。 不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。 什么情况会引发数据库的 flush 过程呢？ InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写 checkpoint 可不是随便往前修改一下位置就可以的。比如图中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。 MySQL 认为系统“空闲”的时候。 MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。 InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。 而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。 所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的： 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。 所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。 InnoDB 刷脏页的控制策略innodb_io_capacity 这个参数，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令： 12fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 所以，InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。 InnoDB 会根据这两个因素先单独算出两个数字。 参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字(F1(M))，计算这个数字的伪代码类似这样： 123456F1(M)&#123; if M&gt;=innodb_max_dirty_pages_pct then return 100; return 100*M/innodb_max_dirty_pages_pct;&#125; InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。 然后，根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。 平时要多关注脏页比例，不要让它经常接近 75%。 其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码： 123mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#x27;Innodb_buffer_pool_pages_dirty&#x27;;select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#x27;Innodb_buffer_pool_pages_total&#x27;;select @a/@b; 接下来，我们再看一个有趣的策略。一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。 在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。 为什么表数据删掉一半，表文件大小不变？参数 innodb_file_per_table表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的： 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起； 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。 从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。 因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。 将 innodb_file_per_table 设置为 ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。 数据删除流程假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。 (也就是逻辑删除) 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。 而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以上 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID&#x3D;50 的记录需要使用新页的时候，page A 是可以被复用的。 如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。 进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。 你现在知道了，delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。 实际上，不止是删除数据会造成空洞，插入数据也会。 如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。假设下图中 page A 已经满了，这时我要再插入一行数据，会怎样呢？可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。 也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的。 重建表试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？ 你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。 由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。 这里，你可以使用 alter table A engine&#x3D;InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。 显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。 而在 MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。 简单描述一下引入了 Online DDL 之后，重建表的流程： 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态； 用临时文件替换表 A 的数据文件。 Online DDL 其实是会先获取MDL写锁, 再退化成MDL读锁；但MDL写锁持有时间比较短，所以可以称为Online； 而MDL读锁，不阻止数据增删查改，但会阻止其它线程修改表结构； count(*)这么慢，我该怎么办？count(*) 的实现方式 MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高； 而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。 MyISAM count 是存储在硬盘，这只是无条件查询的时候，如果有where条件，也是和InnoDB一样 这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。 你知道的，InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 不同的 count 用法count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。 所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。 单看这两个用法的差别的话，能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 对于 count(字段) 来说：如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。 但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。 所以结论是：按照效率排序的话，count(字段)&lt;count(主键 id)&lt;count(1)≈count(*) “order by”是怎么工作的？全字段排序1select city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000 ;(city上有索引) Extra 这个字段中的“Using filesort”表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。从图中可以看到，满足 city&#x3D;’杭州’条件的行，是从 ID_X 到 ID_(X+N) 的这些记录。通常情况下，这个语句执行流程如下所示 ： 初始化 sort_buffer，确定放入 name、city、age 这三个字段； 从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 做快速排序； 按照排序结果取前 1000 行返回给客户端。 图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。 sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。 可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。 1234567891011121314151617/* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace=&#x27;enabled=on&#x27;; /* @a保存Innodb_rows_read的初始值 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = &#x27;Innodb_rows_read&#x27;;/* 执行语句 */select city, name,age from t where city=&#x27;杭州&#x27; order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &#x27;Innodb_rows_read&#x27;;/* 计算Innodb_rows_read差值 */select @b-@a; 这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。number_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件。 如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。 否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。（理解成每一份临时文件也会在内存中排序，sort_buffer_size可以理解成一次内存排序的内存大小，所以每一份临时文件大小就取决于sort_buffer_size的大小） examined_rows&#x3D;4000，表示参与排序的行数是 4000 行。 sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。 同时，最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。 rowid 排序在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。 所以如果单行很大，这个方法效率不够好。 如果 MySQL 认为排序的单行长度太大会怎么做呢? 接下来，修改一个参数，让 MySQL 采用另外一种算法。 1SET max_length_for_sort_data = 16; 上面这个参数是MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。 新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。 但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下所示的样子： 初始化 sort_buffer，确定放入两个字段，即 name 和 id； 从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到不满足 city&#x3D;’杭州’条件为止，也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 进行排序； 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。 对比全字段排序流程你会发现，rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。 需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。需要按顺序使用主键再从索引树上查询，查到一个就返回一个 rowid 排序的 OPTIMIZER_TRACE 部分输出select @b-@a 这个语句的值变成 5000 了。因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行。 sort_mode 变成了 &lt;sort_key, rowid&gt;，表示参与排序的只有 name 和 id 这两个字段。 number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。 这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。 其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。 如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？ 所以，我们可以在表上创建一个 city 和 name 的联合索引在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city&#x3D;’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。 这样整个查询过程的流程就变成了： 从索引 (city,name) 找到第一个满足 city&#x3D;’杭州’条件的主键 id； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回； 从索引 (city,name) 取下一个记录主键 id；重复步骤 2、3， 直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。 图中rows是预估行数,【Using index condition】 使用了索引下推技术ICP 从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。 当然如果想要进步优化，可以使用覆盖索引，针对这个查询，我们可以创建一个 city、name 和 age 的联合索引。 这时，对于 cit y 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了： 从索引 (city,name,age) 找到第一个满足 city&#x3D;’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回； 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回； 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。 可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。 order by rand()1select word from words order by rand() limit 3; 这个语句的意思很直白，随机排序取前 3 个。虽然这个 SQL 语句写法很简单，但执行流程却有点复杂的。 Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。 对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。 语句执行流程: 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。 从内存临时表中一行一行地取出 R 值和位置信息，分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。 如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。 order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。 那么，是不是所有的临时表都是内存表呢？ 其实不是的。**tmp_table_size **这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。 磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。 优先队列排序算法其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。 流程：也就是堆排序 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆； 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)； 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。 1select city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000 ; 这里也用到了 limit，为什么没用优先队列排序算法呢？原因是，这条 SQL 语句是 limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是 1000 行的 (name,rowid)，超过了我设置的 sort_buffer_size 大小，所以只能使用归并排序算法。limit 3 就远不及sort_buffer_size 大小 group by1234567891011121314create table t1(id int primary key, a int, b int, index(a));delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=1000)do insert into t1 values(i, i, i); set i=i+1; end while;end;;delimiter ;call idata(); 1select id%10 as m, count(*) as c from t1 group by m; 在 Extra 字段里面，我们可以看到三个信息： Using index，表示这个语句使用了覆盖索引，选择了索引 a，不需要回表； 因为select用到的实际字段只有id，索引a和主键都能满足这个要求，且索引a叶子节点只存放主键所以体 积更小，于是mysql选择了索引a。 Using temporary，表示使用了临时表； Using filesort，表示需要排序。 语句的执行流程: 创建内存临时表，表里有两个字段 m 和 c，主键是 m； 扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x； 如果临时表中没有主键为 x 的行，就插入一个记录 (x,1); 如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。 group by 优化方法 – 索引可以看到，不论是使用内存临时表还是磁盘临时表，group by 逻辑都需要构造一个带唯一索引的表，执行代价都是比较高的。如果表的数据量比较大，上面这个 group by 语句执行起来就会很慢，我们有什么优化的方法呢？ 执行 group by 语句为什么需要临时表？group by 的语义逻辑，是统计不同的值出现的个数。但是，由于每一行的 id%100 的结果是无序的，所以我们就需要有一个临时表，来记录并统计结果。 那么，如果扫描过程中可以保证出现的数据是有序的，是不是就简单了呢所以在group by的字段上加上索引 就不会在使用临时表了 group by 优化方法 – 直接排序所以，如果可以通过加索引来完成 group by 逻辑就再好不过了。但是，如果碰上不适合创建索引的场景，我们还是要老老实实做排序的。那么，这时候的 group by 要怎么优化呢？ 在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。 1select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m; MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。因此，上面这个语句的执行流程就是这样的： 初始化 sort_buffer，确定放入一个整型字段，记为 m； 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中； 扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）； 排序完成后，就得到了一个有序数组。 根据有序数组，得到数组里面的不同值，以及每个值的出现次数。从 Extra 字段可以看到，这个语句的执行没有再使用临时表，而是直接用了排序算法。如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表； MySQL 什么时候会使用内部临时表？ 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果； join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构； 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。 索引失效的案例1234mysql&gt; select count(*) from tradelog where month(t_modified)=7;t_modified加了索引 运行会发现sql执行很慢，因为如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。如果你的 SQL 语句条件用的是 where t_modified&#x3D;’2018-7-1’的话，引擎就会按照上面绿色箭头的路线，快速定位到 t_modified&#x3D;’2018-7-1’需要的结果。但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在树的第一层就不知道该怎么办了。 也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。但是优化器并不是放弃了这个索引，但是显然无法快速搜索到想要的值，只能全索引扫描，遍历索引树 这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。 不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。 12345select * from tradelog where tradeid=110717;tradeid上有索引tradeid 的字段类型是 varchar(32)tradelog 交易记录表 explain 的结果却显示，这条语句需要走全表扫描。从图中可知，select “10” &gt; 9 返回的是 1，所以就能确认 MySQL 里的转换规则了：在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。字符串比较大小是逐位从高位到低位逐个比较（按ascii码） 那么“10”的“1”的ascii比“9”小，所以结果为0 所以上面这个sql相当于 1mysql&gt; select * from tradelog where CAST(tradid AS signed int) = 110717; 也就是说，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。 select 被阻塞1mysql&gt; select * from t where id=1; 发现查询长时间不返回 一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。 等MDL锁出现这个状态表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，把 select 语句堵住了。 但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema&#x3D;on，相比于设置为 off 会有 10% 左右的性能损失) 通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。 等flush这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个： 12flush tables t with read lock;flush tables with read lock; 这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。 但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了 所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。所以我们只要结束阻塞 flush命令的线程就可以了 等行锁1select * from t where id=1 lock in share mode; 由于访问 id&#x3D;1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。 1mysql&gt; select * from t sys.innodb_lock_waits where locked_table=&#x27;`test`.`t`&#x27;\\G 可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id&#x3D;1 上的行锁。 实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id&#x3D;1 上的行锁 回滚多123select * from t where id=1； 结果：1select * from t where id=1 lock in share mode 结果：1000001这两个查询结果不一样 由于sessionB更新了，sessionA才开始查询，所以sessionB生成了大量的undo log带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；注意，undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑","categories":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]}],"categories":[{"name":"笔记","slug":"笔记","permalink":"http://example.com/categories/%E7%AC%94%E8%AE%B0/"},{"name":"源码","slug":"源码","permalink":"http://example.com/categories/%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"OS","slug":"OS","permalink":"http://example.com/tags/OS/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://example.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"},{"name":"Java基础，JUC","slug":"Java基础，JUC","permalink":"http://example.com/tags/Java%E5%9F%BA%E7%A1%80%EF%BC%8CJUC/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]}